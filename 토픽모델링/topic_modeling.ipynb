{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1ffUnww0499l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: konlpy in /usr/local/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.9/site-packages (from konlpy) (1.21.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.9/site-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.9/site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.9/site-packages (from konlpy) (1.3.0)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.9/site-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.9/site-packages (from konlpy) (4.6.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (2.26.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uCttj98g5LCK"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "token = []\n",
    "with open('news_contents.txt', 'r', encoding='utf-8') as f:\n",
    "    for sentence in f:\n",
    "        token.append(okt.nouns(sentence.replace('\\\"', \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "U3MkHp8N7Zbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['홍콩', '매체', '오징어', '가면', '한국', '핼러윈', '의상', '검색', '중국', '쇼핑', '플랫폼', '오징어', '게임', '상품', '중국', '타오바오', '앱', '스크린샷', '재판매', '및', '금지', '홍콩', '연합뉴스', '윤고은', '특파원', '중국', '넷플릭스', '한국', '드라마', '오징어', '게임', '의', '인기', '타고', '관련', '상품', '역시', '대박', '이', '난', '가운데', '중국', '주요', '온라인쇼핑', '몰이', '돌연', '오징어', '게임', '검색어', '차단', '것', '홍콩', '사우스차이나', '모닝', '포스트', '중국', '대형', '쇼핑', '플랫폼', '타오바오', '징둥', '핀', '지난', '오징어', '게임', '검색어', '입력', '상품', '검색', '보도', '신문', '상황', '오징어', '게임', '관련', '상품', '판매', '업자', '오징어', '가면', '한국', '핼러윈', '의상', '등', '검색어', '치면', '오징어', '게임', '관련', '상품', '검색', '우회', '를', '활용', '전', '저장성', '활동', '판매업', '쩡모', '씨', '대형', '쇼핑', '플랫폼', '오징어', '게임', '검색어', '것', '발견', '그', '이후', '우리', '오징어', '가면', '치면', '오징어', '게임', '관련', '우리', '상품', '검색', '작업', '우리', '바', '오직', '오징어', '게임', '검색어', '해당', '플랫폼', '기능', '말', '우리', '자체', '조사', '이', '플랫폼', '오징어', '게임', '것', '검색', '것', '발견', '해당', '쇼핑', '플랫폼', '이', '관련', '질의', '답', '전', '신문', '판매업', '우회', '검색어', '것', '오징어', '게임', '의', '인기', '덕', '당분간', '관련', '상품', '계속', '수익', '낼', '것임', '전망', '중국', '공장', '국내외', '소비자', '위해', '오징어', '게임', '관련', '상품', '오징어', '게임', '의', '인기', '편승', '중', '등장', '검은색', '가면', '트레이닝복', '소품', '등', '팔고', '부연', '넷플릭스', '서비스', '중국', '오징어', '게임', '이', '불법', '유통', '통해', '선풍', '인기', '끌', '시청', '불법', '관련', '상품', '발', '판매', '저작권', '침해', '지적', '익명', '요구', '판매업', '오징어', '게임', '의', '인기', '얼마나', '더', '알', '수', '판매', '업자', '지금', '기회', '이용', '돈', '말']\n"
     ]
    }
   ],
   "source": [
    "print(token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1s7FmcAj8BXS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: tomotopy in /usr/local/lib/python3.9/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.9/site-packages (from tomotopy) (1.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tomotopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aDdzwnG_8k9D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 #0 로드 완료.\n",
      "문서 #10 로드 완료.\n",
      "문서 #20 로드 완료.\n",
      "문서 #30 로드 완료.\n",
      "문서 #40 로드 완료.\n",
      "문서 #50 로드 완료.\n",
      "문서 #60 로드 완료.\n"
     ]
    }
   ],
   "source": [
    "import tomotopy as tp\n",
    "\n",
    "model = tp.LDAModel(k=20, alpha=0.1, eta=0.01, min_cf=5)\n",
    "\n",
    "for index, sen in enumerate(token):\n",
    "    model.add_doc(sen)\n",
    "    if index % 10 == 0: print('문서 #{} 로드 완료.'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QTopSIiM81dk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문서 수: 70\n",
      "전체 단어 수: 12246\n",
      "단어 크기: 791\n"
     ]
    }
   ],
   "source": [
    "model.train(0) \n",
    "print('전체 문서 수:', len(model.docs))\n",
    "print('전체 단어 수:', model.num_words)\n",
    "print('단어 크기:', model.num_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "K2Q4EbGg6WcD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\tLL per word: -10.914759872698733\n",
      "Iteration 1\tLL per word: -9.041673256304263\n",
      "Iteration 2\tLL per word: -8.15067566047594\n",
      "Iteration 3\tLL per word: -7.642848242376631\n",
      "Iteration 4\tLL per word: -7.343531732570496\n",
      "Iteration 5\tLL per word: -7.165193962200043\n",
      "Iteration 6\tLL per word: -7.03385862654065\n",
      "Iteration 7\tLL per word: -6.92453387617656\n",
      "Iteration 8\tLL per word: -6.852944931679451\n",
      "Iteration 9\tLL per word: -6.794031660472687\n",
      "Iteration 10\tLL per word: -6.738224029326855\n",
      "Iteration 11\tLL per word: -6.736504615587034\n",
      "Iteration 12\tLL per word: -6.69202958810822\n",
      "Iteration 13\tLL per word: -6.6720305395470945\n",
      "Iteration 14\tLL per word: -6.6333328526471345\n",
      "Iteration 15\tLL per word: -6.620353775572567\n",
      "Iteration 16\tLL per word: -6.588299481997337\n",
      "Iteration 17\tLL per word: -6.563526428696885\n",
      "Iteration 18\tLL per word: -6.553137822593522\n",
      "Iteration 19\tLL per word: -6.531692331775758\n",
      "Iteration 20\tLL per word: -6.528405337603424\n",
      "Iteration 21\tLL per word: -6.5223112279622555\n",
      "Iteration 22\tLL per word: -6.522274858674036\n",
      "Iteration 23\tLL per word: -6.507019936673376\n",
      "Iteration 24\tLL per word: -6.488110512385528\n",
      "Iteration 25\tLL per word: -6.486325870836149\n",
      "Iteration 26\tLL per word: -6.466094104681123\n",
      "Iteration 27\tLL per word: -6.4654837411743316\n",
      "Iteration 28\tLL per word: -6.462359045752801\n",
      "Iteration 29\tLL per word: -6.4599453501869375\n",
      "Iteration 30\tLL per word: -6.453495520383495\n",
      "Iteration 31\tLL per word: -6.425460855806164\n",
      "Iteration 32\tLL per word: -6.421718364435144\n",
      "Iteration 33\tLL per word: -6.398812734969258\n",
      "Iteration 34\tLL per word: -6.383598200851516\n",
      "Iteration 35\tLL per word: -6.377221982346316\n",
      "Iteration 36\tLL per word: -6.3649337194639735\n",
      "Iteration 37\tLL per word: -6.349599102429562\n",
      "Iteration 38\tLL per word: -6.343782540675415\n",
      "Iteration 39\tLL per word: -6.337610903563364\n",
      "Iteration 40\tLL per word: -6.330650506756205\n",
      "Iteration 41\tLL per word: -6.324983586891987\n",
      "Iteration 42\tLL per word: -6.323675201002648\n",
      "Iteration 43\tLL per word: -6.316723957511796\n",
      "Iteration 44\tLL per word: -6.303834894042028\n",
      "Iteration 45\tLL per word: -6.305452336604818\n",
      "Iteration 46\tLL per word: -6.307437601331187\n",
      "Iteration 47\tLL per word: -6.2874102855471445\n",
      "Iteration 48\tLL per word: -6.277901917357724\n",
      "Iteration 49\tLL per word: -6.269129923489307\n",
      "Iteration 50\tLL per word: -6.270861108912842\n",
      "Iteration 51\tLL per word: -6.268182367101012\n",
      "Iteration 52\tLL per word: -6.268790714577797\n",
      "Iteration 53\tLL per word: -6.244135611373752\n",
      "Iteration 54\tLL per word: -6.236903546816984\n",
      "Iteration 55\tLL per word: -6.239131501126714\n",
      "Iteration 56\tLL per word: -6.249564513897518\n",
      "Iteration 57\tLL per word: -6.253787215939636\n",
      "Iteration 58\tLL per word: -6.229767383726792\n",
      "Iteration 59\tLL per word: -6.238016914388294\n",
      "Iteration 60\tLL per word: -6.230603717962317\n",
      "Iteration 61\tLL per word: -6.2257915795209575\n",
      "Iteration 62\tLL per word: -6.209603910029139\n",
      "Iteration 63\tLL per word: -6.2114611169286515\n",
      "Iteration 64\tLL per word: -6.205805967115176\n",
      "Iteration 65\tLL per word: -6.20580662722956\n",
      "Iteration 66\tLL per word: -6.197584023209699\n",
      "Iteration 67\tLL per word: -6.2009583818850205\n",
      "Iteration 68\tLL per word: -6.200099934652392\n",
      "Iteration 69\tLL per word: -6.2051478019292965\n",
      "Iteration 70\tLL per word: -6.198919297666423\n",
      "Iteration 71\tLL per word: -6.208632698766589\n",
      "Iteration 72\tLL per word: -6.198374174203083\n",
      "Iteration 73\tLL per word: -6.197332189898563\n",
      "Iteration 74\tLL per word: -6.184322042530334\n",
      "Iteration 75\tLL per word: -6.175627337212892\n",
      "Iteration 76\tLL per word: -6.179415346970944\n",
      "Iteration 77\tLL per word: -6.180268737740441\n",
      "Iteration 78\tLL per word: -6.171186239052964\n",
      "Iteration 79\tLL per word: -6.161326769611015\n",
      "Iteration 80\tLL per word: -6.1668666923126905\n",
      "Iteration 81\tLL per word: -6.177844741894746\n",
      "Iteration 82\tLL per word: -6.178639363114806\n",
      "Iteration 83\tLL per word: -6.188645556277063\n",
      "Iteration 84\tLL per word: -6.178295999217828\n",
      "Iteration 85\tLL per word: -6.148227337857934\n",
      "Iteration 86\tLL per word: -6.156418601946855\n",
      "Iteration 87\tLL per word: -6.169538770531121\n",
      "Iteration 88\tLL per word: -6.16887591771201\n",
      "Iteration 89\tLL per word: -6.177985088726031\n",
      "Iteration 90\tLL per word: -6.172354340616558\n",
      "Iteration 91\tLL per word: -6.154731282786997\n",
      "Iteration 92\tLL per word: -6.160341744383098\n",
      "Iteration 93\tLL per word: -6.154789280335575\n",
      "Iteration 94\tLL per word: -6.141227556719571\n",
      "Iteration 95\tLL per word: -6.132054498852049\n",
      "Iteration 96\tLL per word: -6.137695180020086\n",
      "Iteration 97\tLL per word: -6.146599331883148\n",
      "Iteration 98\tLL per word: -6.1448417944240745\n",
      "Iteration 99\tLL per word: -6.149718002236865\n",
      "Iteration 100\tLL per word: -6.149892459042941\n",
      "Iteration 101\tLL per word: -6.142969058592024\n",
      "Iteration 102\tLL per word: -6.141330995082991\n",
      "Iteration 103\tLL per word: -6.136485592986115\n",
      "Iteration 104\tLL per word: -6.138455955227391\n",
      "Iteration 105\tLL per word: -6.124323250907476\n",
      "Iteration 106\tLL per word: -6.121653976932803\n",
      "Iteration 107\tLL per word: -6.126744060321277\n",
      "Iteration 108\tLL per word: -6.114995444646443\n",
      "Iteration 109\tLL per word: -6.127847260384705\n",
      "Iteration 110\tLL per word: -6.104679515769956\n",
      "Iteration 111\tLL per word: -6.120192408048209\n",
      "Iteration 112\tLL per word: -6.121175595899433\n",
      "Iteration 113\tLL per word: -6.115943538634952\n",
      "Iteration 114\tLL per word: -6.104825211091114\n",
      "Iteration 115\tLL per word: -6.116599022045004\n",
      "Iteration 116\tLL per word: -6.110658119567543\n",
      "Iteration 117\tLL per word: -6.101969738762382\n",
      "Iteration 118\tLL per word: -6.106012026658736\n",
      "Iteration 119\tLL per word: -6.108542239796915\n",
      "Iteration 120\tLL per word: -6.1185248906503755\n",
      "Iteration 121\tLL per word: -6.108446617818981\n",
      "Iteration 122\tLL per word: -6.105886622910481\n",
      "Iteration 123\tLL per word: -6.0995514692433535\n",
      "Iteration 124\tLL per word: -6.107411239452559\n",
      "Iteration 125\tLL per word: -6.108296597951108\n",
      "Iteration 126\tLL per word: -6.105281374271684\n",
      "Iteration 127\tLL per word: -6.09835987465942\n",
      "Iteration 128\tLL per word: -6.099514866474405\n",
      "Iteration 129\tLL per word: -6.101414240885751\n",
      "Iteration 130\tLL per word: -6.112057691636807\n",
      "Iteration 131\tLL per word: -6.1022985603404205\n",
      "Iteration 132\tLL per word: -6.106469517953057\n",
      "Iteration 133\tLL per word: -6.10934328446148\n",
      "Iteration 134\tLL per word: -6.103876417439182\n",
      "Iteration 135\tLL per word: -6.093077142147502\n",
      "Iteration 136\tLL per word: -6.102816524813032\n",
      "Iteration 137\tLL per word: -6.11056149853039\n",
      "Iteration 138\tLL per word: -6.102683559230451\n",
      "Iteration 139\tLL per word: -6.082592251209112\n",
      "Iteration 140\tLL per word: -6.098309247897339\n",
      "Iteration 141\tLL per word: -6.083295555336597\n",
      "Iteration 142\tLL per word: -6.079453674432364\n",
      "Iteration 143\tLL per word: -6.085936836106178\n",
      "Iteration 144\tLL per word: -6.085175759054838\n",
      "Iteration 145\tLL per word: -6.075997179463839\n",
      "Iteration 146\tLL per word: -6.0904026203430615\n",
      "Iteration 147\tLL per word: -6.078749540629252\n",
      "Iteration 148\tLL per word: -6.079309088691629\n",
      "Iteration 149\tLL per word: -6.082038678801977\n",
      "Iteration 150\tLL per word: -6.077339057140289\n",
      "Iteration 151\tLL per word: -6.070928099786517\n",
      "Iteration 152\tLL per word: -6.075918556021433\n",
      "Iteration 153\tLL per word: -6.084762159297518\n",
      "Iteration 154\tLL per word: -6.0831730375074\n",
      "Iteration 155\tLL per word: -6.07943323794366\n",
      "Iteration 156\tLL per word: -6.068508252435779\n",
      "Iteration 157\tLL per word: -6.071054288265986\n",
      "Iteration 158\tLL per word: -6.065452110289399\n",
      "Iteration 159\tLL per word: -6.071438192347773\n",
      "Iteration 160\tLL per word: -6.062932585326068\n",
      "Iteration 161\tLL per word: -6.06494524259447\n",
      "Iteration 162\tLL per word: -6.071638558333107\n",
      "Iteration 163\tLL per word: -6.063029837322628\n",
      "Iteration 164\tLL per word: -6.060590025596655\n",
      "Iteration 165\tLL per word: -6.0636158289569435\n",
      "Iteration 166\tLL per word: -6.051542611066547\n",
      "Iteration 167\tLL per word: -6.04658164436835\n",
      "Iteration 168\tLL per word: -6.05181997204779\n",
      "Iteration 169\tLL per word: -6.048955971049304\n",
      "Iteration 170\tLL per word: -6.052956040602444\n",
      "Iteration 171\tLL per word: -6.052279440781931\n",
      "Iteration 172\tLL per word: -6.054377537115462\n",
      "Iteration 173\tLL per word: -6.038544066499772\n",
      "Iteration 174\tLL per word: -6.04117240616451\n",
      "Iteration 175\tLL per word: -6.031682289884933\n",
      "Iteration 176\tLL per word: -6.030290877572777\n",
      "Iteration 177\tLL per word: -6.052498293372223\n",
      "Iteration 178\tLL per word: -6.044924492072712\n",
      "Iteration 179\tLL per word: -6.0455450404830255\n",
      "Iteration 180\tLL per word: -6.046758776041158\n",
      "Iteration 181\tLL per word: -6.039442553532176\n",
      "Iteration 182\tLL per word: -6.031916705488419\n",
      "Iteration 183\tLL per word: -6.036346981090482\n",
      "Iteration 184\tLL per word: -6.034827809916512\n",
      "Iteration 185\tLL per word: -6.022551896005854\n",
      "Iteration 186\tLL per word: -6.021412010867865\n",
      "Iteration 187\tLL per word: -6.022690527317533\n",
      "Iteration 188\tLL per word: -6.045861315419622\n",
      "Iteration 189\tLL per word: -6.033987781738371\n",
      "Iteration 190\tLL per word: -6.0465711341434965\n",
      "Iteration 191\tLL per word: -6.031806236424711\n",
      "Iteration 192\tLL per word: -6.03092029672977\n",
      "Iteration 193\tLL per word: -6.033727321260878\n",
      "Iteration 194\tLL per word: -6.0448793067021755\n",
      "Iteration 195\tLL per word: -6.036807569857518\n",
      "Iteration 196\tLL per word: -6.027131093391869\n",
      "Iteration 197\tLL per word: -6.023699896448133\n",
      "Iteration 198\tLL per word: -6.0398271426341905\n",
      "Iteration 199\tLL per word: -6.036569107061661\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print('Iteration {}\\tLL per word: {}'.format(i, model.ll_per_word))\n",
    "    model.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "30vjxPyR9BLB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0\t영희, 공원, 올림픽, 등, 서울, 동상, 속, 시민, 꽃, 무궁화\n",
      "Topic #1\t콘텐츠, 스튜디오, 국내, 등, 방송, 제작, 애플, 시장, 산업, 플러스\n",
      "Topic #2\t상대, 빈곤, 율, 한국, 중, 명, 수준, 위, 기준, 더\n",
      "Topic #3\t학교, 폭력, 금지, 학생, 미국, 시청, 미디어, 의상, 핼러윈, 드라마\n",
      "Topic #4\t행사, 이벤트, 인기, 및, 무역, 할인, 서울, 제, 핼로윈, 개최\n",
      "Topic #5\t한국어, 한류, 한국, 식품, 세계, 해외, 전, 종학, 박람회, 케이\n",
      "Topic #6\t상표, 출원, 진, 박성우, 최, 수, 등록, 상표권, 류, 경고\n",
      "Topic #7\t오징어, 프로그램, 예능, 승리, 게임, 영화, 패러디, 공개, 중국, 현지\n",
      "Topic #8\t게임, 구슬, 버스, 콘텐츠, 연구원, 랩, 메타, 매니저, 바이오, 기업\n",
      "Topic #9\t그, 리아노, 태국, 배우, 미국, 영상, 매체, 자신, 캡처, 계산\n",
      "Topic #10\t것, 수, 이, 넷플릭스, 말, 의, 우리, 시리즈, 중, 개\n",
      "Topic #11\t게임, 오징어, 넷플릭스, 한국, 이, 드라마, 위해, 통해, 온라인, 내용\n",
      "Topic #12\t임대료, 연체, 자영, 업자, 정부, 보상금, 손실, 분담, 손실보상, 법\n",
      "Topic #13\t대통령, 대선, 후보, 의원, 이재명, 문, 의혹, 삼양라면, 대장동, 검찰\n",
      "Topic #14\t그, 작품, 때, 감독, 것, 작업, 때문, 더, 정도, 콘텐트\n",
      "Topic #15\t등, 사용, 수, 이용, 코로나, 마련, 서비스, 전, 소비자, 달\n",
      "Topic #16\t게임, 오징어, 드라마, 등, 속, 전, 인기, 명, 대한, 세계\n",
      "Topic #17\t오징어, 판매, 게임, 업체, 관련, 중국, 상품, 온라인, 넷플릭스, 침해\n",
      "Topic #18\t한국, 뉴욕, 미국, 관광, 행사, 문화, 공사, 참가자, 달고나, 관심\n",
      "Topic #19\t제품, 이상, 해당, 대상, 지난, 약, 뉴스, 기사, 경우, 지역\n"
     ]
    }
   ],
   "source": [
    "for i in range(model.k):\n",
    "    # 토픽 개수가 총 20개이니, 0~19번까지의 토픽별 상위 단어 10개를 뽑아봅시다.\n",
    "    res = model.get_topic_words(i, top_n=10)\n",
    "    print('Topic #{}'.format(i), end='\\t')\n",
    "    print(', '.join(w for w, p in res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qD5oYuNo93yv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 #0 로드 완료.\n",
      "문서 #10 로드 완료.\n",
      "문서 #20 로드 완료.\n",
      "문서 #30 로드 완료.\n",
      "문서 #40 로드 완료.\n",
      "문서 #50 로드 완료.\n",
      "문서 #60 로드 완료.\n"
     ]
    }
   ],
   "source": [
    "ctModel = tp.CTModel(k=20, smoothing_alpha=0.1, eta = 0.01, min_cf = 5)\n",
    "\n",
    "for index, sen in enumerate(token):\n",
    "    ctModel.add_doc(sen)\n",
    "    if index % 10 == 0: print('문서 #{} 로드 완료.'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "hqpPjspP-sgO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\tLL per word: -4.421141507054454\n",
      "Iteration 1\tLL per word: -4.395222938624878\n",
      "Iteration 2\tLL per word: -4.407867535452291\n",
      "Iteration 3\tLL per word: -4.433268432672285\n",
      "Iteration 4\tLL per word: -4.398272747478415\n",
      "Iteration 5\tLL per word: -4.398123176103127\n",
      "Iteration 6\tLL per word: -4.386025718056005\n",
      "Iteration 7\tLL per word: -4.383547939755608\n",
      "Iteration 8\tLL per word: -4.378841551404344\n",
      "Iteration 9\tLL per word: -4.368664605139946\n",
      "Iteration 10\tLL per word: -4.377078733718923\n",
      "Iteration 11\tLL per word: -4.374742392857597\n",
      "Iteration 12\tLL per word: -4.359290338086523\n",
      "Iteration 13\tLL per word: -4.330457404978658\n",
      "Iteration 14\tLL per word: -4.357639732862948\n",
      "Iteration 15\tLL per word: -4.339985922713909\n",
      "Iteration 16\tLL per word: -4.349692228666205\n",
      "Iteration 17\tLL per word: -4.335632931267672\n",
      "Iteration 18\tLL per word: -4.364331355549319\n",
      "Iteration 19\tLL per word: -4.341524558919679\n",
      "Iteration 20\tLL per word: -4.349278705171777\n",
      "Iteration 21\tLL per word: -4.376028029541067\n",
      "Iteration 22\tLL per word: -4.385777550914816\n",
      "Iteration 23\tLL per word: -4.364277202366478\n",
      "Iteration 24\tLL per word: -4.368443561044663\n",
      "Iteration 25\tLL per word: -4.377021994638264\n",
      "Iteration 26\tLL per word: -4.3886037564613005\n",
      "Iteration 27\tLL per word: -4.387149209371705\n",
      "Iteration 28\tLL per word: -4.388559404023207\n",
      "Iteration 29\tLL per word: -4.363528052072655\n",
      "Iteration 30\tLL per word: -4.362566568734948\n",
      "Iteration 31\tLL per word: -4.335141714884991\n",
      "Iteration 32\tLL per word: -4.354988426094193\n",
      "Iteration 33\tLL per word: -4.360331277288016\n",
      "Iteration 34\tLL per word: -4.3566258351634755\n",
      "Iteration 35\tLL per word: -4.352833704055256\n",
      "Iteration 36\tLL per word: -4.352040797951426\n",
      "Iteration 37\tLL per word: -4.36360031740885\n",
      "Iteration 38\tLL per word: -4.3614431602876405\n",
      "Iteration 39\tLL per word: -4.360598101894971\n",
      "Iteration 40\tLL per word: -4.364896847308412\n",
      "Iteration 41\tLL per word: -4.378950091244061\n",
      "Iteration 42\tLL per word: -4.363316072251757\n",
      "Iteration 43\tLL per word: -4.358905967197206\n",
      "Iteration 44\tLL per word: -4.355890960306801\n",
      "Iteration 45\tLL per word: -4.371919656040674\n",
      "Iteration 46\tLL per word: -4.359406257082624\n",
      "Iteration 47\tLL per word: -4.350364012281996\n",
      "Iteration 48\tLL per word: -4.340430765381567\n",
      "Iteration 49\tLL per word: -4.334049049680303\n",
      "Iteration 50\tLL per word: -4.319094035524413\n",
      "Iteration 51\tLL per word: -4.315007355292307\n",
      "Iteration 52\tLL per word: -4.331678768337289\n",
      "Iteration 53\tLL per word: -4.354559047637705\n",
      "Iteration 54\tLL per word: -4.351546174809933\n",
      "Iteration 55\tLL per word: -4.328163259533249\n",
      "Iteration 56\tLL per word: -4.3406466107664015\n",
      "Iteration 57\tLL per word: -4.328611288612114\n",
      "Iteration 58\tLL per word: -4.330428948124289\n",
      "Iteration 59\tLL per word: -4.344419760739353\n",
      "Iteration 60\tLL per word: -4.34961519881331\n",
      "Iteration 61\tLL per word: -4.316372390916179\n",
      "Iteration 62\tLL per word: -4.347237665128926\n",
      "Iteration 63\tLL per word: -4.347913678759222\n",
      "Iteration 64\tLL per word: -4.331641172274409\n",
      "Iteration 65\tLL per word: -4.3344077488458295\n",
      "Iteration 66\tLL per word: -4.320748604066267\n",
      "Iteration 67\tLL per word: -4.340961705259924\n",
      "Iteration 68\tLL per word: -4.327204398653894\n",
      "Iteration 69\tLL per word: -4.313643903684016\n",
      "Iteration 70\tLL per word: -4.3258878438837405\n",
      "Iteration 71\tLL per word: -4.321960514613018\n",
      "Iteration 72\tLL per word: -4.329118833617508\n",
      "Iteration 73\tLL per word: -4.355085988231058\n",
      "Iteration 74\tLL per word: -4.321508161508237\n",
      "Iteration 75\tLL per word: -4.357611221942893\n",
      "Iteration 76\tLL per word: -4.334891457807272\n",
      "Iteration 77\tLL per word: -4.359787140935343\n",
      "Iteration 78\tLL per word: -4.323135413177142\n",
      "Iteration 79\tLL per word: -4.343484407412194\n",
      "Iteration 80\tLL per word: -4.352800440597472\n",
      "Iteration 81\tLL per word: -4.3441144653022405\n",
      "Iteration 82\tLL per word: -4.329583390578615\n",
      "Iteration 83\tLL per word: -4.32649923003413\n",
      "Iteration 84\tLL per word: -4.325837514027843\n",
      "Iteration 85\tLL per word: -4.313343224901887\n",
      "Iteration 86\tLL per word: -4.317774947797787\n",
      "Iteration 87\tLL per word: -4.340996527338892\n",
      "Iteration 88\tLL per word: -4.318965144337401\n",
      "Iteration 89\tLL per word: -4.331678763513819\n",
      "Iteration 90\tLL per word: -4.344140804124953\n",
      "Iteration 91\tLL per word: -4.33953438546413\n",
      "Iteration 92\tLL per word: -4.348949722484516\n",
      "Iteration 93\tLL per word: -4.335892935735074\n",
      "Iteration 94\tLL per word: -4.3377662948532745\n",
      "Iteration 95\tLL per word: -4.316301326908532\n",
      "Iteration 96\tLL per word: -4.334874307162112\n",
      "Iteration 97\tLL per word: -4.33046170757883\n",
      "Iteration 98\tLL per word: -4.30966942366891\n",
      "Iteration 99\tLL per word: -4.302168896713522\n",
      "Iteration 100\tLL per word: -4.353129344089308\n",
      "Iteration 101\tLL per word: -4.327909281905348\n",
      "Iteration 102\tLL per word: -4.332232629987085\n",
      "Iteration 103\tLL per word: -4.352906610266107\n",
      "Iteration 104\tLL per word: -4.323727806956769\n",
      "Iteration 105\tLL per word: -4.315828821106969\n",
      "Iteration 106\tLL per word: -4.324274832902075\n",
      "Iteration 107\tLL per word: -4.309724062194471\n",
      "Iteration 108\tLL per word: -4.3286217624321885\n",
      "Iteration 109\tLL per word: -4.330044766868249\n",
      "Iteration 110\tLL per word: -4.318140213476489\n",
      "Iteration 111\tLL per word: -4.340443883580372\n",
      "Iteration 112\tLL per word: -4.339814508991188\n",
      "Iteration 113\tLL per word: -4.344321896912381\n",
      "Iteration 114\tLL per word: -4.336027717005773\n",
      "Iteration 115\tLL per word: -4.339153720361334\n",
      "Iteration 116\tLL per word: -4.343093906399201\n",
      "Iteration 117\tLL per word: -4.3365460096300374\n",
      "Iteration 118\tLL per word: -4.359196156163573\n",
      "Iteration 119\tLL per word: -4.357778387167632\n",
      "Iteration 120\tLL per word: -4.363810583963691\n",
      "Iteration 121\tLL per word: -4.344273435016697\n",
      "Iteration 122\tLL per word: -4.34373160089647\n",
      "Iteration 123\tLL per word: -4.3309879640864715\n",
      "Iteration 124\tLL per word: -4.344185290965534\n",
      "Iteration 125\tLL per word: -4.363960550946191\n",
      "Iteration 126\tLL per word: -4.339907505842896\n",
      "Iteration 127\tLL per word: -4.319061237686545\n",
      "Iteration 128\tLL per word: -4.356168815588374\n",
      "Iteration 129\tLL per word: -4.333486350814482\n",
      "Iteration 130\tLL per word: -4.35874589492763\n",
      "Iteration 131\tLL per word: -4.364102897023903\n",
      "Iteration 132\tLL per word: -4.343483691682506\n",
      "Iteration 133\tLL per word: -4.3115494757575545\n",
      "Iteration 134\tLL per word: -4.295049864122841\n",
      "Iteration 135\tLL per word: -4.319863777061936\n",
      "Iteration 136\tLL per word: -4.335617799095282\n",
      "Iteration 137\tLL per word: -4.336402538419743\n",
      "Iteration 138\tLL per word: -4.350905090268679\n",
      "Iteration 139\tLL per word: -4.354188825476993\n",
      "Iteration 140\tLL per word: -4.329194566173193\n",
      "Iteration 141\tLL per word: -4.321655242958626\n",
      "Iteration 142\tLL per word: -4.3299869858963556\n",
      "Iteration 143\tLL per word: -4.322310281232079\n",
      "Iteration 144\tLL per word: -4.364993303870621\n",
      "Iteration 145\tLL per word: -4.328557482706883\n",
      "Iteration 146\tLL per word: -4.343528659497428\n",
      "Iteration 147\tLL per word: -4.321130615372041\n",
      "Iteration 148\tLL per word: -4.3318845938423305\n",
      "Iteration 149\tLL per word: -4.343583246921473\n",
      "Iteration 150\tLL per word: -4.325882315326609\n",
      "Iteration 151\tLL per word: -4.338647163578172\n",
      "Iteration 152\tLL per word: -4.353808556949997\n",
      "Iteration 153\tLL per word: -4.342317208637385\n",
      "Iteration 154\tLL per word: -4.3429008729971255\n",
      "Iteration 155\tLL per word: -4.348872322579425\n",
      "Iteration 156\tLL per word: -4.369455446028133\n",
      "Iteration 157\tLL per word: -4.371793277511166\n",
      "Iteration 158\tLL per word: -4.36746854273377\n",
      "Iteration 159\tLL per word: -4.3585471496407004\n",
      "Iteration 160\tLL per word: -4.344491962173708\n",
      "Iteration 161\tLL per word: -4.372842861167574\n",
      "Iteration 162\tLL per word: -4.360790012889529\n",
      "Iteration 163\tLL per word: -4.379476746551239\n",
      "Iteration 164\tLL per word: -4.359118937720212\n",
      "Iteration 165\tLL per word: -4.351116858606495\n",
      "Iteration 166\tLL per word: -4.352941120642376\n",
      "Iteration 167\tLL per word: -4.374742180612787\n",
      "Iteration 168\tLL per word: -4.362540394369535\n",
      "Iteration 169\tLL per word: -4.352511619042016\n",
      "Iteration 170\tLL per word: -4.36081885465284\n",
      "Iteration 171\tLL per word: -4.362933256348986\n",
      "Iteration 172\tLL per word: -4.351814073948066\n",
      "Iteration 173\tLL per word: -4.340303626720659\n",
      "Iteration 174\tLL per word: -4.358932331932072\n",
      "Iteration 175\tLL per word: -4.356151506831015\n",
      "Iteration 176\tLL per word: -4.354146302994824\n",
      "Iteration 177\tLL per word: -4.378148316494998\n",
      "Iteration 178\tLL per word: -4.345183588602117\n",
      "Iteration 179\tLL per word: -4.349908750537717\n",
      "Iteration 180\tLL per word: -4.356456331729831\n",
      "Iteration 181\tLL per word: -4.3618446656706755\n",
      "Iteration 182\tLL per word: -4.364468834640815\n",
      "Iteration 183\tLL per word: -4.370759026553995\n",
      "Iteration 184\tLL per word: -4.347267896961527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 185\tLL per word: -4.3367127103902305\n",
      "Iteration 186\tLL per word: -4.362569255897632\n",
      "Iteration 187\tLL per word: -4.355799032032378\n",
      "Iteration 188\tLL per word: -4.355299760317532\n",
      "Iteration 189\tLL per word: -4.340009162485083\n",
      "Iteration 190\tLL per word: -4.337257748254638\n",
      "Iteration 191\tLL per word: -4.343731860176189\n",
      "Iteration 192\tLL per word: -4.358897930531647\n",
      "Iteration 193\tLL per word: -4.359363802888319\n",
      "Iteration 194\tLL per word: -4.330613391110365\n",
      "Iteration 195\tLL per word: -4.352173486452841\n",
      "Iteration 196\tLL per word: -4.337054815546722\n",
      "Iteration 197\tLL per word: -4.357718247521767\n",
      "Iteration 198\tLL per word: -4.347954821558865\n",
      "Iteration 199\tLL per word: -4.346574308897338\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print('Iteration {}\\tLL per word: {}'.format(i, ctModel.ll_per_word))\n",
    "    ctModel.train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QJE8Zjd3-_9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0\t콘텐츠, 문화, 최, 관광, 공사, 산업, 시장, 애플, 지원, 식품\n",
      "Topic #1\t제작, 참여, 를, 리지, 시민, 스튜디오, 큐브, 널, 랩, 글로벌\n",
      "Topic #2\t위, 반응, 기준, 대선, 문제, 정부, 기사, 부분, 다음, 연구원\n",
      "Topic #3\t중국, 지난, 개, 더, 전, 최근, 고, 수준, 예능, 매체\n",
      "Topic #4\t학교, 것, 임대료, 감독, 핼러윈, 점, 령, 소비자, 시설, 진흥\n",
      "Topic #5\t그, 한국어, 학생, 수, 사람, 종학, 때, 제보자, 언어, 과거\n",
      "Topic #6\t한류, 상표, 영희, 출원, 빈곤, 율, 박성우, 진, 등록, 동상\n",
      "Topic #7\t판매, 우리, 대통령, 침해, 리아노, 제품, 태국, 나, 브랜드, 언급\n",
      "Topic #8\t오징어, 폭력, 금지, 공원, 시청, 서울, 올림픽, 의상, 속, 복장\n",
      "Topic #9\t오징어, 게임, 의, 작품, 배우, 대상, 실제, 주장, 이, 보도\n",
      "Topic #10\t국내, 스튜디오, 기업, 경우, 촬영, 때문, 등, 버스, 플러스, 메타\n",
      "Topic #11\t수, 통해, 업체, 해외, 이용, 모두, 검색, 지역, 보호, 이벤트\n",
      "Topic #12\t행사, 속, 등, 달고나, 뉴스, 무궁화, 진행, 꽃, 관심, 구슬\n",
      "Topic #13\t수, 사진, 공개, 일, 정도, 가장, 한국, 미국인, 문화, 직접\n",
      "Topic #14\t프로그램, 오징어, 영화, 사용, 미디어, 은, 플랫폼, 승리, 내용, 그\n",
      "Topic #15\t것, 중, 다른, 이상, 생각, 대해, 안, 라며, 세, 영국\n",
      "Topic #16\t한국, 전, 상품, 방송, 상대, 달, 때, 경제, 유통, 맨해튼\n",
      "Topic #17\t게임, 미국, 명, 뉴욕, 참가자, 현지, 우려, 초록색, 이후, 놀이\n",
      "Topic #18\t게임, 드라마, 넷플릭스, 온라인, 기자, 속, 시간, 해당, 앞, 사진\n",
      "Topic #19\t등, 이, 세계, 인기, 대한, 관련, 말, 위해, 내, 서비스\n"
     ]
    }
   ],
   "source": [
    "for i in range(ctModel.k):\n",
    "    # 토픽 개수가 총 20개이니, 0~19번까지의 토픽별 상위 단어 10개를 뽑아봅시다.\n",
    "    res = ctModel.get_topic_words(i, top_n=10)\n",
    "    print('Topic #{}'.format(i), end='\\t')\n",
    "    print(', '.join(w for w, p in res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "g = Network(width=800, height=800, font_color=\"#333\")\n",
    "correl = ctModel.get_correlations().reshape([-1])\n",
    "correl.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0 한국 관광 문화 공사 직접 참가자 사장 맨해튼\n",
      "Topic #1 스튜디오 임대료 예능 승리 등록 패러디 시설 큐브\n",
      "Topic #2 상대 대통령 율 기준 플러스 대선 후보 결제\n",
      "Topic #3 이 중 지난 고 최근 공개 수준 매체\n",
      "Topic #4 수 때 최 대한 방송 금지 미디어 감독\n",
      "Topic #5 그 리아노 우리 학생 작업 태국 영상 무엇\n",
      "Topic #6 상표 영희 출원 작품 빈곤 진 박성우 동상\n",
      "Topic #7 판매 상품 제품 침해 검색 브랜드 유통 경고\n",
      "Topic #8 학교 폭력 공원 올림픽 의상 핼러윈 우려 시청\n",
      "Topic #9 게임 오징어 중국 무궁화 꽃 치기 이후 놀이\n",
      "Topic #10 콘텐츠 한국어 한류 애플 버스 메타 산업 진흥\n",
      "Topic #11 등 국내 업체 기업 사용 해외 경우 개\n",
      "Topic #12 뉴욕 행사 달고나 진행 제 관심 식품 정말\n",
      "Topic #13 사람 그 다른 생각 법 정도 자신 내\n",
      "Topic #14 프로그램 제작 영화 안 내용 글로벌 장면 주장\n",
      "Topic #15 것 의 말 더 시리즈 넷플릭스 은 리지\n",
      "Topic #16 한국 수 명 위 가장 달 참여 해당\n",
      "Topic #17 드라마 속 미국 인기 위해 참가자 현지 서울\n",
      "Topic #18 오징어 게임 사진 를 시간 보도 우리 등장\n",
      "Topic #19 등 넷플릭스 전 세계 이 온라인 관련 통해\n"
     ]
    }
   ],
   "source": [
    "top_tenth = ctModel.k * (ctModel.k - 1) // 10\n",
    "top_tenth = correl[-ctModel.k - top_tenth]\n",
    " \n",
    "topic_counts = ctModel.get_count_by_topics()\n",
    " \n",
    "for k in range(ctModel.k):\n",
    "    label = \"#{}\".format(k)\n",
    "    title= ' '.join(word for word, _ in ctModel.get_topic_words(k, top_n=8))\n",
    "    print('Topic', label, title)\n",
    "    label += '\\n' + ' '.join(word for word, _ in ctModel.get_topic_words(k, top_n=3))\n",
    "    g.add_node(k, label=label, title=title, shape='ellipse', value=float(topic_counts[k]))\n",
    "    for l, correlation in zip(range(k - 1), ctModel.get_correlations(k)):\n",
    "        if correlation < top_tenth: continue\n",
    "        g.add_edge(k, l, value=float(correlation), title='{:.02}'.format(correlation))\n",
    " \n",
    "g.barnes_hut(gravity=-1000, spring_length=20)\n",
    "g.show_buttons()\n",
    "# 시각화 파일이 topic_network.html 이라는 이름으로 저장됩니다.\n",
    "# 웹 브라우저로 열어서 확인해보세요.\n",
    "g.show(\"topic_network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Fzv0KLUNARaH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 #0 로드 완료.\n",
      "문서 #10 로드 완료.\n",
      "문서 #20 로드 완료.\n",
      "문서 #30 로드 완료.\n",
      "문서 #40 로드 완료.\n",
      "문서 #50 로드 완료.\n",
      "문서 #60 로드 완료.\n"
     ]
    }
   ],
   "source": [
    "hdpModel = tp.HDPModel(initial_k = 20, alpha=0.1, eta=0.01, min_cf=5)\n",
    "\n",
    "for index, sen in enumerate(token):\n",
    "    hdpModel.add_doc(sen)\n",
    "    if index % 10 == 0: print('문서 #{} 로드 완료.'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Cz1B3R1ZBFXH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\tLL per word: 0.0\n",
      "Iteration 1\tLL per word: -6.528071897512321\n",
      "Iteration 2\tLL per word: -6.337604533588304\n",
      "Iteration 3\tLL per word: -6.301215679061855\n",
      "Iteration 4\tLL per word: -6.281609015528641\n",
      "Iteration 5\tLL per word: -6.267097245881746\n",
      "Iteration 6\tLL per word: -6.275754835799145\n",
      "Iteration 7\tLL per word: -6.238004602347054\n",
      "Iteration 8\tLL per word: -6.222614388226022\n",
      "Iteration 9\tLL per word: -6.217644625038721\n",
      "Iteration 10\tLL per word: -6.195283095470231\n",
      "Iteration 11\tLL per word: -6.199071270800797\n",
      "Iteration 12\tLL per word: -6.189795119221569\n",
      "Iteration 13\tLL per word: -6.184864683301546\n",
      "Iteration 14\tLL per word: -6.186982196996789\n",
      "Iteration 15\tLL per word: -6.162805320954529\n",
      "Iteration 16\tLL per word: -6.151316786462646\n",
      "Iteration 17\tLL per word: -6.133919805322385\n",
      "Iteration 18\tLL per word: -6.125597617409304\n",
      "Iteration 19\tLL per word: -6.125900834521378\n",
      "Iteration 20\tLL per word: -6.123270337359298\n",
      "Iteration 21\tLL per word: -6.113227992768033\n",
      "Iteration 22\tLL per word: -6.120352919518743\n",
      "Iteration 23\tLL per word: -6.115266258588477\n",
      "Iteration 24\tLL per word: -6.113776161139957\n",
      "Iteration 25\tLL per word: -6.104728741445671\n",
      "Iteration 26\tLL per word: -6.1017450381586915\n",
      "Iteration 27\tLL per word: -6.099186243077187\n",
      "Iteration 28\tLL per word: -6.088387039699489\n",
      "Iteration 29\tLL per word: -6.087194957920836\n",
      "Iteration 30\tLL per word: -6.089273352590277\n",
      "Iteration 31\tLL per word: -6.088889189177666\n",
      "Iteration 32\tLL per word: -6.083020726586603\n",
      "Iteration 33\tLL per word: -6.079348053512436\n",
      "Iteration 34\tLL per word: -6.078348589628794\n",
      "Iteration 35\tLL per word: -6.077617101881136\n",
      "Iteration 36\tLL per word: -6.076879356142237\n",
      "Iteration 37\tLL per word: -6.081483952344564\n",
      "Iteration 38\tLL per word: -6.082179790148252\n",
      "Iteration 39\tLL per word: -6.085989819424966\n",
      "Iteration 40\tLL per word: -6.087647777454109\n",
      "Iteration 41\tLL per word: -6.0871257566654196\n",
      "Iteration 42\tLL per word: -6.0824131599228775\n",
      "Iteration 43\tLL per word: -6.086700754910926\n",
      "Iteration 44\tLL per word: -6.082144240859519\n",
      "Iteration 45\tLL per word: -6.079351814182954\n",
      "Iteration 46\tLL per word: -6.088944862096426\n",
      "Iteration 47\tLL per word: -6.094968703531779\n",
      "Iteration 48\tLL per word: -6.079214865468636\n",
      "Iteration 49\tLL per word: -6.0817997795138\n",
      "Iteration 50\tLL per word: -6.068322675632687\n",
      "Iteration 51\tLL per word: -6.065590657791476\n",
      "Iteration 52\tLL per word: -6.070075319285644\n",
      "Iteration 53\tLL per word: -6.085625326109735\n",
      "Iteration 54\tLL per word: -6.073598480606203\n",
      "Iteration 55\tLL per word: -6.073413923268378\n",
      "Iteration 56\tLL per word: -6.063100318844054\n",
      "Iteration 57\tLL per word: -6.0653375335014585\n",
      "Iteration 58\tLL per word: -6.070954984335967\n",
      "Iteration 59\tLL per word: -6.071568835079524\n",
      "Iteration 60\tLL per word: -6.069594537882795\n",
      "Iteration 61\tLL per word: -6.067357144382252\n",
      "Iteration 62\tLL per word: -6.064645675726621\n",
      "Iteration 63\tLL per word: -6.068097437204887\n",
      "Iteration 64\tLL per word: -6.064213636477127\n",
      "Iteration 65\tLL per word: -6.066563093154119\n",
      "Iteration 66\tLL per word: -6.06556657461409\n",
      "Iteration 67\tLL per word: -6.062103042644592\n",
      "Iteration 68\tLL per word: -6.061891061173688\n",
      "Iteration 69\tLL per word: -6.0696956455444715\n",
      "Iteration 70\tLL per word: -6.069707805748647\n",
      "Iteration 71\tLL per word: -6.043096864630384\n",
      "Iteration 72\tLL per word: -6.033000984262762\n",
      "Iteration 73\tLL per word: -6.028921135321135\n",
      "Iteration 74\tLL per word: -6.026880848004735\n",
      "Iteration 75\tLL per word: -6.022104231824132\n",
      "Iteration 76\tLL per word: -6.0231961834456005\n",
      "Iteration 77\tLL per word: -6.025839023977134\n",
      "Iteration 78\tLL per word: -6.0214296088739685\n",
      "Iteration 79\tLL per word: -6.022425265517009\n",
      "Iteration 80\tLL per word: -6.029072156922793\n",
      "Iteration 81\tLL per word: -6.026398190384341\n",
      "Iteration 82\tLL per word: -6.025359309675568\n",
      "Iteration 83\tLL per word: -6.022008979493801\n",
      "Iteration 84\tLL per word: -6.025623329301373\n",
      "Iteration 85\tLL per word: -6.0271010537290035\n",
      "Iteration 86\tLL per word: -6.0257038186037635\n",
      "Iteration 87\tLL per word: -6.026599447516547\n",
      "Iteration 88\tLL per word: -6.024556616367749\n",
      "Iteration 89\tLL per word: -6.01955308317262\n",
      "Iteration 90\tLL per word: -6.019113703527891\n",
      "Iteration 91\tLL per word: -6.01705291345971\n",
      "Iteration 92\tLL per word: -6.0333681240904165\n",
      "Iteration 93\tLL per word: -6.039878466404596\n",
      "Iteration 94\tLL per word: -6.034021943082378\n",
      "Iteration 95\tLL per word: -6.033393029194729\n",
      "Iteration 96\tLL per word: -6.036081310017872\n",
      "Iteration 97\tLL per word: -6.027417342101712\n",
      "Iteration 98\tLL per word: -6.0311257347218765\n",
      "Iteration 99\tLL per word: -6.041625567575149\n",
      "Iteration 100\tLL per word: -6.039249865833147\n",
      "Iteration 101\tLL per word: -6.039778439998237\n",
      "Iteration 102\tLL per word: -6.039849066450065\n",
      "Iteration 103\tLL per word: -6.031763952190768\n",
      "Iteration 104\tLL per word: -6.033481570740999\n",
      "Iteration 105\tLL per word: -6.018249840493414\n",
      "Iteration 106\tLL per word: -6.015423490665093\n",
      "Iteration 107\tLL per word: -6.025738590218829\n",
      "Iteration 108\tLL per word: -6.0253505996292605\n",
      "Iteration 109\tLL per word: -6.030423329270939\n",
      "Iteration 110\tLL per word: -6.026820975289944\n",
      "Iteration 111\tLL per word: -6.018588914934296\n",
      "Iteration 112\tLL per word: -6.011252739802113\n",
      "Iteration 113\tLL per word: -6.010024925121661\n",
      "Iteration 114\tLL per word: -6.010262626556522\n",
      "Iteration 115\tLL per word: -6.006426761396839\n",
      "Iteration 116\tLL per word: -6.006293600570838\n",
      "Iteration 117\tLL per word: -6.011431999500916\n",
      "Iteration 118\tLL per word: -6.007567044568377\n",
      "Iteration 119\tLL per word: -6.008792887983146\n",
      "Iteration 120\tLL per word: -6.014438850786607\n",
      "Iteration 121\tLL per word: -6.022992551940028\n",
      "Iteration 122\tLL per word: -6.008717185995771\n",
      "Iteration 123\tLL per word: -6.013814955253763\n",
      "Iteration 124\tLL per word: -6.013976231696811\n",
      "Iteration 125\tLL per word: -6.01993745844796\n",
      "Iteration 126\tLL per word: -6.021056024326952\n",
      "Iteration 127\tLL per word: -6.022336942083049\n",
      "Iteration 128\tLL per word: -6.019058586081979\n",
      "Iteration 129\tLL per word: -6.017252764436285\n",
      "Iteration 130\tLL per word: -6.022152934766723\n",
      "Iteration 131\tLL per word: -6.020718695582779\n",
      "Iteration 132\tLL per word: -6.021790456639461\n",
      "Iteration 133\tLL per word: -6.026103812515512\n",
      "Iteration 134\tLL per word: -6.0197551210740805\n",
      "Iteration 135\tLL per word: -6.018265608983474\n",
      "Iteration 136\tLL per word: -6.019186316275546\n",
      "Iteration 137\tLL per word: -6.022900337567813\n",
      "Iteration 138\tLL per word: -6.019804471403131\n",
      "Iteration 139\tLL per word: -6.022551469839458\n",
      "Iteration 140\tLL per word: -6.02334147178716\n",
      "Iteration 141\tLL per word: -6.015779738583519\n",
      "Iteration 142\tLL per word: -6.007813448768103\n",
      "Iteration 143\tLL per word: -6.00052150748591\n",
      "Iteration 144\tLL per word: -6.0291901814008915\n",
      "Iteration 145\tLL per word: -6.033978980973365\n",
      "Iteration 146\tLL per word: -6.016483216489742\n",
      "Iteration 147\tLL per word: -6.014918207051453\n",
      "Iteration 148\tLL per word: -6.011480330544789\n",
      "Iteration 149\tLL per word: -6.013274773670609\n",
      "Iteration 150\tLL per word: -6.0029287489142344\n",
      "Iteration 151\tLL per word: -6.008214684613639\n",
      "Iteration 152\tLL per word: -6.010011396220399\n",
      "Iteration 153\tLL per word: -6.02112948045648\n",
      "Iteration 154\tLL per word: -6.022733914079219\n",
      "Iteration 155\tLL per word: -6.021221241140296\n",
      "Iteration 156\tLL per word: -6.018644106907917\n",
      "Iteration 157\tLL per word: -6.010564968123772\n",
      "Iteration 158\tLL per word: -6.008794315184874\n",
      "Iteration 159\tLL per word: -6.00661018471809\n",
      "Iteration 160\tLL per word: -6.009033994816417\n",
      "Iteration 161\tLL per word: -6.012127449441225\n",
      "Iteration 162\tLL per word: -6.005460442329337\n",
      "Iteration 163\tLL per word: -6.003504465573679\n",
      "Iteration 164\tLL per word: -6.009423467432695\n",
      "Iteration 165\tLL per word: -6.001413577973171\n",
      "Iteration 166\tLL per word: -6.008094644051994\n",
      "Iteration 167\tLL per word: -6.007912289292209\n",
      "Iteration 168\tLL per word: -6.012598054618904\n",
      "Iteration 169\tLL per word: -6.00530639234836\n",
      "Iteration 170\tLL per word: -6.009976768112058\n",
      "Iteration 171\tLL per word: -6.009574768221224\n",
      "Iteration 172\tLL per word: -6.003088469737381\n",
      "Iteration 173\tLL per word: -6.002518526755885\n",
      "Iteration 174\tLL per word: -6.008316865606711\n",
      "Iteration 175\tLL per word: -6.00171823897199\n",
      "Iteration 176\tLL per word: -5.997978162126916\n",
      "Iteration 177\tLL per word: -6.008203258316598\n",
      "Iteration 178\tLL per word: -6.000914114685439\n",
      "Iteration 179\tLL per word: -6.000031667169979\n",
      "Iteration 180\tLL per word: -6.009182310408088\n",
      "Iteration 181\tLL per word: -6.003817140520661\n",
      "Iteration 182\tLL per word: -5.997833739985015\n",
      "Iteration 183\tLL per word: -5.997800017695947\n",
      "Iteration 184\tLL per word: -6.005298628091384\n",
      "Iteration 185\tLL per word: -6.008200933316866\n",
      "Iteration 186\tLL per word: -6.002665880535156\n",
      "Iteration 187\tLL per word: -6.0054719933843606\n",
      "Iteration 188\tLL per word: -5.99371326380494\n",
      "Iteration 189\tLL per word: -6.0034812469021395\n",
      "Iteration 190\tLL per word: -6.000586154529827\n",
      "Iteration 191\tLL per word: -5.997565729135628\n",
      "Iteration 192\tLL per word: -5.999079628257839\n",
      "Iteration 193\tLL per word: -6.001707313128124\n",
      "Iteration 194\tLL per word: -5.988734555598783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 195\tLL per word: -6.0001539566850575\n",
      "Iteration 196\tLL per word: -5.986185760430295\n",
      "Iteration 197\tLL per word: -5.99248225638704\n",
      "Iteration 198\tLL per word: -5.99672302579872\n",
      "Iteration 199\tLL per word: -5.994820535367909\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print('Iteration {}\\tLL per word: {}'.format(i, hdpModel.ll_per_word))\n",
    "    hdpModel.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "khER_HqTBObh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0\t한국, 게임, 뉴욕, 오징어, 드라마, 참가자, 속, 미국, 관광, 행사\n",
      "Topic #1\t영희, 공원, 게임, 오징어, 올림픽, 등, 동상, 무궁화, 속, 전시\n",
      "Topic #2\t게임, 오징어, 등, 메타, 버스, 플랫폼, 드라마, 관련, 이용자, 제페토\n",
      "Topic #3\t대통령, 대선, 이재명, 문, 후보, 정권, 대장동, 청와대, 것, 특검\n",
      "Topic #4\t게임, 오징어, 넷플릭스, 드라마, 한국, 위해, 명, 제공, 의사, 고\n",
      "Topic #5\t게임, 오징어, 예능, 프로그램, 패러디, 현지, 배우, 사진, 공개, 영화\n",
      "Topic #6\t게임, 오징어, 학교, 폭력, 드라마, 학생, 금지, 이, 미국, 수\n",
      "Topic #7\t빈곤, 것, 상대, 명, 율, 한국, 위, 중, 수준, 더\n",
      "Topic #8\t리아노, 게임, 그, 오징어, 태국, 것, 지난, 계산, 제보자, 배우\n",
      "Topic #9\t감독, 작업, 걸리버, 기술, 를, 혁, 우리, 글로벌, 그림, 하나\n",
      "Topic #10\t것, 게임, 오징어, 수, 작품, 때문, 때, 정도, 그, 콘텐트\n",
      "Topic #11\t콘텐츠, 등, 한류, 세계, 전, 산업, 한국, 케이, 박람회, 수출\n",
      "Topic #12\t서울, 게임, 기자, 연합뉴스, 오징어, 드라마, 오후, 넷플릭스, 로봇, 속\n",
      "Topic #13\t임대료, 연체, 자영, 업자, 정부, 보상금, 법, 손실, 손실보상, 분담\n",
      "Topic #14\t상표, 출원, 오징어, 게임, 최, 수, 박성우, 진, 상표권, 등록\n",
      "Topic #15\t오징어, 게임, 것, 관련, 이, 검색어, 중국, 상품, 플랫폼, 인기\n",
      "Topic #16\t바이오, 등, 콘텐츠, 업종, 상, 상대, 최근, 의, 현상, 상위\n",
      "Topic #17\t무역, 구자열, 회의, 회장, 차, 제, 확대, 협회, 성장, 대해\n",
      "Topic #18\t기업, 달, 공연, 상담, 시장, 국내, 투자, 및, 대표, 가장\n",
      "Topic #19\t등, 게임, 오징어, 업체, 중국, 전, 넷플릭스, 판매, 결제, 상품\n",
      "Topic #20\t랩, 및, 학회, 이벤트, 스토어, 이, 진행, 시약, 관심, 달고나\n",
      "Topic #21\t할인, 롯데, 아울렛, 인기, 최대, 브랜드, 점, 일, 고객, 행사\n",
      "Topic #22\t언급, 대한, 뉴스, 배, 총회, 제, 차, 현실, 시간, 은\n",
      "Topic #23\t애플, 국내, 시장, 디즈니, 진출, 것, 독자, 한국, 를, 투자\n",
      "Topic #24\t플러스, 콘텐츠, 넷플릭스, 리지, 서비스, 역시, 경쟁, 강, 앞서, 중\n",
      "Topic #25\t의원, 검찰, 라며, 수사, 것, 안, 얘기, 민주당, 이, 생각\n",
      "Topic #26\t구슬, 제품, 사탕, 세븐일레븐, 실제, 업계, 판매, 해당, 치기, 만큼\n",
      "Topic #27\t행사, 참석, 예술, 이정재, 오징어, 및, 미국, 개최, 자리, 업계\n",
      "Topic #28\t작품, 것, 게임, 생각, 이, 내, 오징어, 두, 감독, 방송\n",
      "Topic #29\t한국어, 종학, 이, 교육, 재단, 이사장, 전, 해외, 언어, 앞\n",
      "Topic #30\t교수, 논의, 미디어, 방송, 한국, 게임, 학교, 학회, 대한, 오징어\n",
      "Topic #31\t참여, 이상, 오징어, 개국, 로, 조사, 가운데, 여, 국민, 사진\n",
      "Topic #32\t오징어, 중국, 게임, 프로그램, 표절, 승리, 비판, 이, 비난, 한국\n",
      "Topic #33\t핼로윈, 속초, 갯배, 행사, 이벤트, 공연, 이용, 분위기, 지역, 수\n",
      "Topic #34\t유쿠, 현지, 문화, 최근, 서비스, 내용, 반응, 그, 스트리밍, 로고\n",
      "Topic #35\t등, 판매, 게임, 오징어, 업체, 적발, 뉴스, 가면, 온라인, 넷플릭스\n",
      "Topic #36\t광고, 기사, 정국, 표시, 게시, 조사, 경우, 개방, 출처, 법\n",
      "Topic #37\t식품, 상품, 온라인, 우리, 줄리아, 노, 말, 연관, 실시간, 유통\n",
      "Topic #38\t자리, 하루, 팀, 저, 일이, 이제, 별로, 집, 현장, 전환\n",
      "Topic #39\t것, 국내, 제품, 중국산, 쇼핑몰, 표시, 중국, 본부, 인기, 위원회\n",
      "Topic #40\t우리, 실제, 사전, 계기, 행, 운동복, 축제, 기회, 현상, 일부\n",
      "Topic #41\t시민, 인형, 술래, 달고나, 중, 코리안, 관련, 오전, 유통, 입\n",
      "Topic #42\t미국, 청소년, 미디어, 오징어, 드라마, 시청, 게임, 폭력, 기업, 소아\n",
      "Topic #43\t매니저, 연구원, 삼양라면, 세대, 삼양식품, 이미지, 브랜드, 광고, 면, 기념\n",
      "Topic #44\t타고, 그, 트레이닝복, 시민, 선물, 요원, 분야, 집중, 이름, 주인공\n",
      "Topic #45\t시청, 관련, 관계자, 쇼핑몰, 과, 홈페이지, 제한, 전문, 자, 대응\n",
      "Topic #46\t승리, 금지, 오징어, 및, 베, 캡처, 트위터, 상, 의혹, 저작권\n",
      "Topic #47\t수, 여우쿠, 다른, 사용, 여기, 게임, 등, 넷플릭스, 아시아, 직접\n",
      "Topic #48\t스튜디오, 큐브, 제작, 시설, 수상, 촬영, 방송, 목적, 운영, 진흥\n",
      "Topic #49\t한국, 드라마, 게임, 문화, 콘텐츠, 세계, 사람, 오징어, 보고, 더\n",
      "Topic #50\t끌, 개인, 승리, 로, 해당, 드라마, 수, 넷플릭스, 이, 속\n",
      "Topic #51\t우선, 겨냥, 바, 흥행, 한국, 드라마, 수, 넷플릭스, 이, 속\n",
      "Topic #52\t리지, 널, 시리즈, 이번, 라며, 테마, 가운데, 끌, 린다, 구슬\n",
      "Topic #53\t게임, 오징어, 등, 것, 한국, 드라마, 수, 넷플릭스, 이, 속\n",
      "Topic #54\t게임, 오징어, 등, 것, 한국, 드라마, 수, 넷플릭스, 이, 속\n"
     ]
    }
   ],
   "source": [
    "for i in range(hdpModel.k):\n",
    "    # 토픽 개수가 총 20개이니, 0~19번까지의 토픽별 상위 단어 10개를 뽑아봅시다.\n",
    "    res = hdpModel.get_topic_words(i, top_n=10)\n",
    "    print('Topic #{}'.format(i), end='\\t')\n",
    "    print(', '.join(w for w, p in res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "P_41osZfFdUz"
   },
   "outputs": [],
   "source": [
    "with open('newsData.txt', 'w', encoding='utf-8') as f:\n",
    "    for doc in token:\n",
    "        line = \" \".join(doc) + \"\\n\"\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JCaMW1p_I_pF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Sumin Lim (KAIST)\n",
    "Description: This file implements LDA model and saves result file. Users should prepare tokenized \n",
    "text file as input file of this program.\n",
    "Usage: python lda.py -tkf tokenized_filename\n",
    "\"\"\"\n",
    "import argparse\n",
    "import pandas as pd \n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LDA:\n",
    "    def __init__(self, tokenized_file):\n",
    "        self.tokenized = tokenized_file\n",
    "\n",
    "    def read_data(self):\n",
    "        print(\"Read Data ... \")\n",
    "        tokenized_words = []\n",
    "        split_lines = []\n",
    "        with open(self.tokenized, \"r\", encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                tokenized_words.append(line.strip())\n",
    "                split_lines.append([x for x in line.strip().split()])\n",
    "\n",
    "        return tokenized_words, split_lines\n",
    "\n",
    "    def get_tf(self):\n",
    "        print(\"Get term frequency ... \")\n",
    "        term_count = Counter(chain.from_iterable(self.document_split))\n",
    "        df_idf = pd.DataFrame(term_count.items(), columns=[\"Term\", \"Freq\"])\n",
    "        return df_idf\n",
    "\n",
    "    def get_tfidf_score(self):\n",
    "        print(\"Get Tf-idf Score ... \")\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X = vectorizer.fit_transform(self.document)\n",
    "        self.X = X\n",
    "\n",
    "        # Tf-idf Full Matrix (sparse)\n",
    "        df_full = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "        # Tf-idf matrix with row format of document_id, token_id, tf-idf score\n",
    "        doc_size = X.shape[0]; term_size = X.shape[1]\n",
    "        terms = vectorizer.get_feature_names()\n",
    "        doc_id = []; term_id = []; score = []\n",
    "\n",
    "        for doc in tqdm(range(doc_size)):\n",
    "            for term in range(term_size):\n",
    "                if X[doc, term] != 0:\n",
    "                    doc_id.append(doc)\n",
    "                    term_id.append(terms[term])\n",
    "                    score.append(X[doc, term])\n",
    "\n",
    "        df_tfidf = pd.DataFrame({\"Document\": doc_id, \n",
    "                                 \"Term\": term_id,\n",
    "                                 \"Score\": score})\n",
    "\n",
    "        return df_full, df_tfidf\n",
    "\n",
    "    def lda(self, is_graph):\n",
    "        print(\"Analyze LDA ... \")\n",
    "        alpha = input(\"Please enter the alpha: \")\n",
    "        iterations = int(input(\"Please enter the number of iterations: \"))\n",
    "        is_tfidf = input(\"Using Tf-idf (y/n): \")\n",
    "\n",
    "        id2word = corpora.Dictionary(self.document_split)\n",
    "        corpus = [id2word.doc2bow(text) for text in self.document_split]\n",
    "\n",
    "        if is_tfidf == \"y\":\n",
    "            tfidf = gensim.models.TfidfModel(corpus)\n",
    "            corpus = tfidf[corpus]\n",
    "\n",
    "\n",
    "        if is_graph == \"y\":\n",
    "            if alpha == \"auto\":\n",
    "                alpha = \"asymmetric\"\n",
    "            perplexities = []; coherences = []\n",
    "\n",
    "            start = int(input(\"Please enter the starting number of topic: \"))\n",
    "            end = int(input(\"Please enter the end number of topic: \"))\n",
    "            step = int(input(\"Please enter the step to increase: \"))\n",
    "\n",
    "            for num_topic in tqdm(range(start, end+1, step)):\n",
    "                lda_model = LdaMulticore(corpus=corpus,\n",
    "                                         num_topics=num_topic,\n",
    "                                         id2word=id2word,\n",
    "                                         chunksize=100,\n",
    "                                         alpha=alpha,\n",
    "                                         iterations=iterations,\n",
    "                                         per_word_topics=True)\n",
    "\n",
    "                perplexities.append(lda_model.log_perplexity(corpus))\n",
    "\n",
    "                coherence = CoherenceModel(model=lda_model,\n",
    "                                           texts=self.document_split,\n",
    "                                           dictionary=id2word,\n",
    "                                           coherence=\"c_v\")\n",
    "                coherences.append(coherence.get_coherence())\n",
    "\n",
    "            x_topic = range(start, end+1, step)\n",
    "            plt.plot(x_topic, perplexities)\n",
    "            plt.xlabel(\"The Number of Topics\")\n",
    "            plt.ylabel(\"Log Perplexity\")\n",
    "            plt.savefig(\"log_perplexities_\"+\"from_\"+str(start)+\"_to_\"+str(end+1)+\".png\", bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "\n",
    "            plt.plot(x_topic, coherences)\n",
    "            plt.xlabel(\"The Number of Topics\")\n",
    "            plt.ylabel(\"Coherence Score\")\n",
    "            plt.savefig(\"coherence_score_\"+\"from_\"+str(start)+\"_to_\"+str(end+1)+\".png\", bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        elif is_graph == \"n\":\n",
    "            num_topics = input(\"Please enter the number of topics: \")\n",
    "            lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=num_topics,\n",
    "                                                        random_state=100,\n",
    "                                                        update_every=1,\n",
    "                                                        chunksize=100,\n",
    "                                                        alpha=alpha,\n",
    "                                                        iterations=iterations,\n",
    "                                                        per_word_topics=True)\n",
    "\n",
    "            # Perplexity and Coherence Score\n",
    "            print(\"Get log perplexity and coherence score ... \")\n",
    "            print(\"\\nPerplexity: \", lda_model.log_perplexity(corpus))\n",
    "\n",
    "            coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                                 texts=self.document_split, \n",
    "                                                 dictionary=id2word,\n",
    "                                                 coherence=\"c_v\")\n",
    "            coherence_lda = coherence_model_lda.get_coherence()\n",
    "            print(\"\\nCoherence Score: \", coherence_lda)\n",
    "\n",
    "            # Save LDA, corpus, dictionary for visualizing\n",
    "            print(\"Save LDA model, corpus, dictionary for future visualizing ... \")\n",
    "            with open(\"corpus\", \"wb\") as f:\n",
    "                pkl.dump(corpus, f)\n",
    "\n",
    "            with open(\"dictionary\", \"wb\") as f:\n",
    "                pkl.dump(id2word, f)\n",
    "\n",
    "            with open(\"lda_model\", \"wb\") as f:\n",
    "                pkl.dump(lda_model, f)\n",
    "\n",
    "            doc_lda = lda_model[corpus]\n",
    "\n",
    "            # Get topic words \n",
    "            print(\"Get topic words ... \")\n",
    "            columns = []\n",
    "            for k, v in id2word.iteritems():\n",
    "                columns.append(v)\n",
    "\n",
    "            df_topic = []\n",
    "            topics = lda_model.get_topics()\n",
    "            for idx, topic in enumerate(topics):\n",
    "                temp = list([v, topic[k]] for k, v in zip(id2word.keys(), id2word.values()))\n",
    "                df_temp = pd.DataFrame(temp, columns=[\"Topic\"+str(idx+1)+\"_term\",\n",
    "                                                      \"Topic\"+str(idx+1)+\"_weight\"])\n",
    "                df_temp = df_temp.sort_values(by=[\"Topic\"+str(idx+1)+\"_weight\"], ascending=False)\n",
    "                df_temp = df_temp.reset_index(drop=True)\n",
    "                df_topic.append(df_temp)\n",
    "\n",
    "            df_topic = pd.concat(df_topic, axis=1)\n",
    "\n",
    "            # Get Document-Topic Distribution\n",
    "            print(\"Get Document-Topic Distribution ... \")\n",
    "            doc_topic = lda_model.get_document_topics(doc_lda)\n",
    "            dict_doc_topic = {}\n",
    "            for idx, doc in enumerate(doc_topic):\n",
    "                dict_doc_topic[idx] = [x[1] for x in doc]\n",
    "\n",
    "            df_doc_topic = pd.DataFrame(dict_doc_topic).transpose()\n",
    "            df_doc_topic.rename(columns={col:\"Topic-\"+str(col+1) for col in df_doc_topic.columns}, inplace=True)\n",
    "            df_doc_topic.rename(index={x:\"Document\"+str(x+1) for x in df_doc_topic.index}, inplace=True)\n",
    "\n",
    "            print(\"Get topic weight ... \")\n",
    "            df_topic_weight = pd.DataFrame(df_doc_topic.sum(axis=0)).reset_index()\n",
    "            df_topic_weight.rename(columns={\"index\":\"Topic\",\n",
    "                                            0: \"Weight (Sum)\"}, inplace=True)\n",
    "            weight_sum = sum(df_topic_weight[\"Weight (Sum)\"])\n",
    "            df_topic_weight[\"Weight (%)\"] = df_topic_weight[\"Weight (Sum)\"].apply(lambda x: x/weight_sum * 100)\n",
    "            df_topic_weight[\"Rank\"] = df_topic_weight[\"Weight (%)\"].rank(axis=0, ascending=False)\n",
    "\n",
    "            return df_topic, df_doc_topic, df_topic_weight\n",
    "\n",
    "    def similarity(self):\n",
    "        print(\"Get cosine similarity ... \")\n",
    "        cos_sim = linear_kernel(self.X, self.X)\n",
    "        df_sim = pd.DataFrame(cos_sim)\n",
    "        df_sim.rename(columns={col:\"Document\"+str(col) for col in df_sim.columns}, inplace=True)\n",
    "        df_sim.rename(index={col:\"Document\"+str(col) for col in df_sim.index}, inplace=True)\n",
    "        return df_sim\n",
    "\n",
    "    def main(self):\n",
    "        self.document, self.document_split = self.read_data()\n",
    "        self.df_tf = self.get_tf()\n",
    "        self.tfidf_sparse, self.tfidf_dense = self.get_tfidf_score()\n",
    "        self.df_sim = self.similarity()\n",
    "\n",
    "        is_graph = input(\"Please enter whether you want perplexity and coherence graph or not (y/n): \")\n",
    "        if is_graph == \"n\":\n",
    "            self.df_topic, self.df_doc_topic, self.df_topic_weight = self.lda(is_graph)\n",
    "\n",
    "            print(\"Save result file ... \")\n",
    "            with pd.ExcelWriter(\"LDA_result.xlsx\") as writer:\n",
    "                self.df_tf.to_excel(writer, sheet_name=\"TF\", index=False, encoding=\"utf-8\")\n",
    "                self.tfidf_sparse.to_excel(writer, sheet_name=\"TFIDF_sparse\", index=False, encoding=\"utf-8\")\n",
    "                self.tfidf_dense.to_excel(writer, sheet_name=\"TFIDF_dense\", index=False, encoding=\"utf-8\")\n",
    "                self.df_topic.to_excel(writer, sheet_name=\"Topic-Keyword\", index=False, encoding=\"utf-8\")\n",
    "                self.df_doc_topic.to_excel(writer, sheet_name=\"Topic-Document\", encoding=\"utf-8\")\n",
    "                self.df_topic_weight.to_excel(writer, sheet_name=\"Topic-Weight\", index=False, encoding=\"utf-8\")\n",
    "                self.df_sim.to_excel(writer, sheet_name=\"Document-Similarity\", encoding=\"utf-8\")\n",
    "        elif is_graph == \"y\":\n",
    "            self.lda(is_graph)\n",
    "\n",
    "        print(\"All work is done. Bye!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.0.9-py2.py3-none-any.whl (242 kB)\n",
      "     |████████████████████████████████| 242 kB 5.0 MB/s            \n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "OrXN67HeJjcr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Data ... \n",
      "Get term frequency ... \n",
      "Get Tf-idf Score ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 70/70 [00:02<00:00, 24.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get cosine similarity ... \n",
      "Please enter whether you want perplexity and coherence graph or not (y/n): n\n",
      "Analyze LDA ... \n",
      "Please enter the alpha: auto\n",
      "Please enter the number of iterations: 20\n",
      "Using Tf-idf (y/n): y\n",
      "Please enter the number of topics: 20\n",
      "Get log perplexity and coherence score ... \n",
      "\n",
      "Perplexity:  -17.628778522094542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.39201138989742046\n",
      "Save LDA model, corpus, dictionary for future visualizing ... \n",
      "Get topic words ... \n",
      "Get Document-Topic Distribution ... \n",
      "Get topic weight ... \n",
      "Save result file ... \n",
      "All work is done. Bye!\n"
     ]
    }
   ],
   "source": [
    "lda = LDA('newsData.txt')\n",
    "lda.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: pyLDAvis==2.1.2 in /usr/local/lib/python3.9/site-packages (2.1.2)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.9/site-packages (from pyLDAvis==2.1.2) (1.3.1)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.9/site-packages (from pyLDAvis==2.1.2) (0.36.2)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.9/site-packages (from pyLDAvis==2.1.2) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.9/site-packages (from pyLDAvis==2.1.2) (1.7.0)\n",
      "Requirement already satisfied: funcy in /usr/local/lib/python3.9/site-packages (from pyLDAvis==2.1.2) (1.16)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.9/site-packages (from pyLDAvis==2.1.2) (1.21.0)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.9/site-packages (from pyLDAvis==2.1.2) (2.7.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.9/site-packages (from pyLDAvis==2.1.2) (0.18.2)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.9/site-packages (from pyLDAvis==2.1.2) (6.2.5)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.9/site-packages (from pyLDAvis==2.1.2) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/site-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/site-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2021.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.9/site-packages (from pytest->pyLDAvis==2.1.2) (1.10.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from pytest->pyLDAvis==2.1.2) (21.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/site-packages (from pytest->pyLDAvis==2.1.2) (1.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/site-packages (from pytest->pyLDAvis==2.1.2) (21.2.0)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.9/site-packages (from pytest->pyLDAvis==2.1.2) (1.1.1)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.9/site-packages (from pytest->pyLDAvis==2.1.2) (0.10.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis==2.1.2) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging->pytest->pyLDAvis==2.1.2) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis==2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import pickle as pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = pkl.load(open(\"lda_model\", \"rb\"))\n",
    "corpus = pkl.load(open(\"corpus\", \"rb\"))\n",
    "dictionary = pkl.load(open(\"dictionary\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma, _ = lda.inference(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pyLDAvis/_prepare.py:228: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info  = pd.DataFrame({'saliency': saliency, 'Term': vocab, \\\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/usr/local/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "prepared_data = gensimvis.prepare(lda, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el7521261727016326099861003\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el7521261727016326099861003_data = {\"mdsDat\": {\"x\": [0.0022407507136745974, -0.0027381653975835016, -0.02437883527850687, 0.011448472951181997, 0.01467273753406073, -0.010974841634259028, -0.0054635609437700345, -0.00024355056334473968, 0.011491424002478443, 0.0018255001258986204, -0.002232606824220296, -0.0016697787627552119, 0.0017182002142148755, -0.005579753156118136, 0.00526514501713211, 0.0016190851684323544, -0.0028158642674573167, 0.0008701502705310271, 0.0037436818916408857, 0.001201808938769508], \"y\": [-0.02329895001678013, 0.002078578875989057, -0.006053780489620456, 0.006138477780930887, 0.0033739398701170876, 0.005251378181924042, -0.003324445192072521, 0.011018388519780615, -0.012924478986936857, -0.0006693554908197586, 0.007868890405566561, -0.003722038000005324, 0.0014027696813029452, 0.0054517273513702575, 0.005349989995830662, 0.0024213754218986895, 0.00021322160651059566, 0.003392501740678648, -0.0031000841196633304, -0.0008681071360016578], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [8.14516901219705, 7.803662677739448, 7.253103777437551, 6.955320338825103, 6.709278347100129, 6.416106140273656, 6.356601208764684, 5.964942454126959, 5.443160716087038, 5.215123888255197, 5.121740028742098, 4.641756336948626, 4.199672420599072, 3.9720069195225367, 3.691504303496016, 3.471189230583898, 3.3826763260995207, 2.4509474669913396, 2.155760859463249, 0.650277546746834]}, \"tinfo\": {\"Term\": [\"\\uc601\\ud76c\", \"\\ub9ac\\uc544\\ub178\", \"\\uacf5\\uc6d0\", \"\\uba54\\ud0c0\", \"\\ube48\\uace4\", \"\\uc784\\ub300\\ub8cc\", \"\\uacb0\\uc81c\", \"\\uc62c\\ub9bc\\ud53d\", \"\\ubc84\\uc2a4\", \"\\uc728\", \"\\ub300\\ud1b5\\ub839\", \"\\uad6c\\uc2ac\", \"\\uc608\\ub2a5\", \"\\uc5ec\\uc6b0\\ucfe0\", \"\\ud55c\\uad6d\\uc5b4\", \"\\ud57c\\ub85c\\uc708\", \"\\uc720\\ucfe0\", \"\\ud559\\uad50\", \"\\ub274\\uc695\", \"\\uc5c5\\uccb4\", \"\\ub3d9\\uc0c1\", \"\\ud55c\\ub958\", \"\\uc911\\uad6d\", \"\\uc0c1\\ub300\", \"\\uc904\\ub9ac\\uc544\", \"\\uc870\\ud615\", \"\\ubc29\\uc774\\ub3d9\", \"\\ub958\\ud6a8\\ub9bc\", \"\\uad00\\uad11\", \"\\ub178\", \"\\ub9ac\\uc544\\ub178\", \"\\ud560\\uc778\", \"\\uc774\\ubcd1\\ud5cc\", \"\\uc544\\uc6b8\\ub81b\", \"\\ub86f\\ub370\", \"\\ud544\\ub984\", \"\\uc18c\\uc18d\\uc0ac\", \"\\uc81c\\ubcf4\\uc790\", \"\\ud5a5\", \"\\uc608\\uc220\", \"\\uc544\\ud2b8\", \"\\uc5d4\\ud130\\ud14c\\uc778\\uba3c\\ud2b8\", \"\\uacc4\\uc0b0\", \"\\uac08\\ub77c\", \"\\ud0dc\\uad6d\", \"\\uc774\\uc815\\uc7ac\", \"\\ub2f9\\uc2dc\", \"\\uacfc\\uac70\", \"\\uace0\\uac1d\", \"\\uc9c0\\uc0ac\", \"\\uc778\\uc885\\ucc28\\ubcc4\", \"\\uc0c8\\uce58\\uae30\", \"\\ucd5c\\ub300\", \"\\ub098\", \"\\uc81c\\ud504\\ub9ac\", \"\\uc608\\uc220\\uac00\", \"\\uc871\\uc801\", \"\\uce74\\uc6b4\\ud2f0\", \"\\uba85\\uc778\", \"\\ub85c\\uc2a4\\uc564\\uc824\\ub808\\uc2a4\", \"\\ucd9c\\uc5f0\", \"\\ucc38\\uc11d\", \"\\uadf8\", \"\\uc0e4\\ud06c\", \"\\uc810\", \"\\ub274\\uc695\", \"\\uad00\\uad11\", \"\\ud589\\uc0ac\", \"\\ud55c\\uad6d\", \"\\ucd2c\\uc601\\uc7a5\", \"\\ud574\\uc591\", \"\\ud050\\ube0c\", \"\\ud55c\\uc885\", \"\\uac74\\uad6d\", \"\\uc131\\uc2e0\", \"\\uc6b4\\ub3d9\\uc7a5\", \"\\ucc2c\", \"\\uc18c\\uc544\", \"\\ubcf5\\ud569\", \"\\ud14c\\ub9c8\", \"\\ub300\\ud559\\uad50\", \"\\uc218\\uc0c1\", \"\\ub9b0\\ub2e4\", \"\\uc2a4\\ud29c\\ub514\\uc624\", \"\\uc218\\uc870\", \"\\uc9c0\\ub9ac\\uc0b0\", \"\\uccad\\ubb38\\ud68c\", \"\\uc758\\ud68c\", \"\\uc801\\ubc1c\", \"\\uc624\\ud508\", \"\\ud55c\\ubcf4\", \"\\uc5b4\\uac00\", \"\\uacc4\\ud68d\", \"\\uc811\\uadfc\", \"\\ubc88\\uac00\", \"\\ub274\\uc695\\uc2dc\", \"\\uc9d1\\uacb0\", \"\\uc18c\\uac10\", \"\\ud574\\uc0b0\", \"\\ub2e8\\uc18d\", \"\\uc2e4\\ub0b4\", \"\\uccad\\uc18c\\ub144\", \"\\uc5b4\\ub978\", \"\\ub274\\uc695\", \"\\ucc38\\uac00\\uc790\", \"\\ud589\\uc0ac\", \"\\uae00\\ub85c\\ubc8c\", \"\\uc11c\\uc6b8\", \"\\ud55c\\uad6d\", \"\\uad00\\uad11\", \"\\uc758\\uc0c1\", \"\\uc624\\ud6c4\", \"\\ub9e8\\ud574\\ud2bc\", \"\\ubbf8\\ub514\\uc5b4\", \"\\uc0bc\\uc591\\ub77c\\uba74\", \"\\ubb34\\uc5ed\", \"\\ud68c\\uc7a5\", \"\\uc0bc\\uc591\\uc2dd\\ud488\", \"\\ud328\\ub7ec\\ub514\", \"\\uad6c\\uc790\\uc5f4\", \"\\uc608\\ub2a5\", \"\\ucd5c\\uc911\\ub77d\", \"\\ubd80\\uc2a4\", \"\\uc6cc\\uc2f1\\ud134\", \"\\ud0a8\\ud14d\\uc2a4\", \"\\uae40\\ubd80\\uacb8\", \"\\uad6d\\ubb34\\ucd1d\\ub9ac\", \"\\uac1c\\ub9c9\\uc2dd\", \"\\uacbd\\uae30\\ub3c4\", \"\\ub85c\\ubcf4\", \"\\ud611\\ud68c\\uc7a5\", \"\\ubc31\\uc2b9\", \"\\ub85c\\ubd07\\uc0b0\\uc5c5\", \"\\uc6d4\\ub4dc\", \"\\ub82c\", \"\\uace0\\uc591\\uc2dc\", \"\\uc528\\ub984\", \"\\ud398\\uc2a4\\ud2f0\\ubc8c\", \"\\uc0bc\\uc591\", \"\\uc870\\uc815\", \"\\ud68c\\uc758\", \"\\uad11\\uc7a5\", \"\\ucf54\\ub9ac\\uc548\", \"\\ucc38\\uc11d\\uc790\", \"\\uc2dc\\ubbfc\", \"\\ud504\\ub85c\\uadf8\\ub7a8\", \"\\ub85c\\ubd07\", \"\\ub274\\uc695\", \"\\ud55c\\uad6d\", \"\\uae30\\ud6c4\\ubcc0\\ud654\", \"\\uc0ac\\uad6d\", \"\\uc720\\uc5d4\", \"\\ud611\\uc57d\", \"\\uc815\\uce58\\uc778\", \"\\uc5b8\\uae09\", \"\\uc815\\uc0c1\", \"\\uad8c\\ub825\", \"\\uc5c5\\uccb4\", \"\\ucd1d\\ud68c\", \"\\uba54\\uc544\\ub9ac\", \"\\ub0a8\\uc870\\uc120\", \"\\uc791\\uc804\", \"\\uc18c\\ud0d5\", \"\\ub300\\uad8c\", \"\\uc8fc\\uc778\\uacf5\", \"\\ubc30\", \"\\uae30\\ud6c4\", \"\\uc724\\ud558\", \"\\ub370\\uc774\\ud130\", \"\\uc9c0\\uc801\\uc7ac\\uc0b0\\uad8c\", \"\\ub300\\uc120\", \"\\uc5f0\\uc77c\", \"\\uce68\\ud574\", \"\\ub9e4\\uccb4\", \"\\uc120\\uc804\", \"\\uc9c4\\uc9dc\", \"\\ubd81\\ud55c\", \"\\ud0c0\\uc624\\ubc14\\uc624\", \"\\uc54c\\ub9ac\\ubc14\\ubc14\", \"\\uc1fc\\ud551\\ubab0\", \"\\uc911\\uad6d\", \"\\ucc28\", \"\\uc0c1\\ud488\", \"\\uace0\", \"\\ud3ed\\ub825\", \"\\uc628\\ub77c\\uc778\", \"\\ud559\\uad50\", \"\\uc758\\uc6d0\", \"\\ud559\\ud68c\", \"\\ub9e4\\ub2c8\\uc800\", \"\\ub7a9\", \"\\uc5f0\\uad6c\\uc6d0\", \"\\uac80\\ucc30\", \"\\ub17c\\uc758\", \"\\uc2dc\\uc57d\", \"\\uad50\\uc218\", \"\\ub9cc\\ub4dc\", \"\\ud559\\uc220\", \"\\ud1a0\\ub860\", \"\\ubbf8\\ub514\\uc5b4\", \"\\ud55c\\ud654\", \"\\uace0\\ubd84\\uc790\", \"\\uc5f0\\uad6c\\uc18c\", \"\\uc218\\uc0ac\", \"\\uc18c\\ube44\", \"\\ud654\\ucc9c\", \"\\uacfd\", \"\\ubd80\", \"\\ub300\\uc720\", \"\\uc9c4\\uc2e4\", \"\\ubc29\\uc1a1\", \"\\ud658\\uacbd\", \"\\ubd80\\ubaa8\", \"\\ubcc0\\ud638\\uc0ac\", \"\\uc624\\ud574\", \"\\uc5f0\\uad6c\\uc2e4\", \"\\ub178\", \"\\uc801\\ubc1c\", \"\\ucd9c\\uc6d0\", \"\\ud559\\uad50\", \"\\uc774\\ubca4\\ud2b8\", \"\\ud3ed\\ub825\", \"\\uc5c5\\uccb4\", \"\\uadf8\", \"\\ub300\\ud55c\", \"\\ud55c\\ub958\", \"\\ubc14\\uc774\\uc624\", \"\\ubc15\\ub78c\\ud68c\", \"\\uc2a4\\ud29c\\ub514\\uc624\", \"\\ucf00\\uc774\", \"\\uc5c5\\uc885\", \"\\uc218\\uc775\\ub960\", \"\\uc9c0\\uc218\", \"\\uc2b9\\ub960\", \"\\uc2dc\\uc124\", \"\\ucf58\\ud150\\uce20\", \"\\uc2dd\\ud488\", \"\\uc870\\ud615\", \"\\ubc29\\uc774\\ub3d9\", \"\\ub958\\ud6a8\\ub9bc\", \"\\uc0c1\", \"\\ubcd1\\ubaa9\", \"\\ub274\\ub51c\", \"\\uac15\\uc138\", \"\\uc6d0\\uc720\", \"\\uc8fc\\uac00\", \"\\uc99d\\uc2dc\", \"\\uc704\\uba54\\uc774\\ub4dc\", \"\\ud654\\uc7a5\\ud488\", \"\\uc0b0\\uc5c5\", \"\\uac15\\ud0dc\\uc6b1\", \"\\uad6c\\ucd95\", \"\\uc120\\ubb3c\", \"\\uc7a5\\uad00\", \"\\uc218\\uc0c1\", \"\\uae30\\ub150\", \"\\ud050\\ube0c\", \"\\uae30\\uc5c5\", \"\\ucd2c\\uc601\", \"\\ubb3c\", \"\\uc1a1\\ud30c\\uad6c\", \"\\uc9c0\\uc6d0\", \"\\uc124\\uce58\", \"\\uc794\\ub514\", \"\\uc11c\\uc6b8\", \"\\uc2dc\\ubbfc\", \"\\ub9c8\\ub2f9\", \"\\ubc29\\uc1a1\", \"\\ub85c\\ubd07\", \"\\ud55c\\uad6d\", \"\\uc62c\\ub9bc\\ud53d\", \"\\uc220\\ub798\", \"\\uacf5\\uc6d0\", \"\\uc601\\ud76c\", \"\\uc804\\uc2dc\", \"\\ub3d9\\uc0c1\", \"\\uc778\\ud615\", \"\\uad00\\uad11\", \"\\uacf5\\uc0ac\", \"\\uae40\\uc815\\ub0a8\", \"\\ubc15\\ubb3c\\uad00\", \"\\uc18c\\ubb38\", \"\\ub9e8\\ud574\\ud2bc\", \"\\ud615\\uc2dd\", \"\\uacf5\\uc6d0\", \"\\uc2a4\\ud0c0\", \"\\uc9c0\\uc6d0\", \"\\uaf43\", \"\\uc5f0\\uc2b5\", \"\\uc774\\uacbd\\ud76c\", \"\\ubb34\\uad81\\ud654\", \"\\uc2e4\\uac10\", \"\\uc720\\ub2c8\\ud3fc\", \"\\uba54\\ud2b8\\ub85c\\ud3f4\\ub9ac\\ud0c4\", \"\\ub274\\uc695\", \"\\ub77c\\uc778\", \"\\uc911\\uc2ec\\uc9c0\", \"\\uc99d\\ub300\", \"\\uc774\\ub370\\uc77c\\ub9ac\", \"\\ubcc4\\ub3c4\", \"\\uc774\\ub3d9\", \"\\ud504\\ub80c\\uc988\", \"\\uc74c\\uc131\", \"\\uc5ec\\ud589\", \"\\uc62c\\ub9bc\\ud53d\", \"\\ud55c\\uad6d\", \"\\uc9c1\\uc811\", \"\\uc9c0\\uc0ac\", \"\\uc2dc\\ubbfc\", \"\\ub531\\uc9c0\", \"\\ucc38\\uac00\\uc790\", \"\\ud604\\uc9c0\", \"\\ub0b4\", \"\\uc220\\ub798\", \"\\ubbf8\\uad6d\", \"\\uc5ec\\uc6b0\\ucfe0\", \"\\uc601\\ud76c\", \"\\ub3d9\\uc0c1\", \"\\ubc15\\uc131\\uc6b0\", \"\\uc2b9\\ub9ac\", \"\\ucd9c\\uc6d0\", \"\\ub124\\ud2f0\\uc98c\", \"\\uad00\\ucc30\\uc790\", \"\\uc0c1\\ud45c\", \"\\ube48\\uace4\", \"\\uc728\", \"\\ud559\\uad50\", \"\\uc57c\\uc678\", \"\\ud57c\\ub7ec\\uc708\\ub370\\uc774\", \"\\uc0c1\\ud45c\\uad8c\", \"\\ucee4\\ubba4\\ub2c8\\ud2f0\", \"\\uc0c1\\ub300\", \"\\ud559\\uc0dd\", \"\\uc804\\ub0a0\", \"\\ud504\\ub85c\\uadf8\\ub7a8\", \"\\uc5e3\\uc2dc\", \"\\uc18c\\ub4dd\", \"\\ud559\\ubd80\\ubaa8\", \"\\ub9dd\", \"\\uce21\\uc740\", \"\\uae08\\uc9c0\", \"\\ud45c\\uc808\", \"\\uacf5\\uc6d0\", \"\\ud3ed\\ub825\", \"\\uc2dc\\uccad\", \"\\uc62c\\ub9bc\\ud53d\", \"\\ubcf5\\uc7a5\", \"\\uc9c4\", \"\\uae30\\uc900\", \"\\uc758\\uc0c1\", \"\\ud57c\\ub7ec\\uc708\", \"\\uc911\\uad6d\", \"\\ub300\\ud1b5\\ub839\", \"\\ud57c\\ub85c\\uc708\", \"\\uac80\\uc0c9\\uc5b4\", \"\\uc18d\\ucd08\", \"\\ud50c\\ub7ec\\uc2a4\", \"\\uc560\\ud50c\", \"\\uac2f\\ubc30\", \"\\uc774\\uc7ac\\uba85\", \"\\uc1fc\\ud551\", \"\\ub514\\uc988\\ub2c8\", \"\\ud310\\ub9e4\\uc5c5\", \"\\ub300\\uc120\", \"\\uc815\\uad8c\", \"\\uccad\\ub144\", \"\\uc9c4\\ucd9c\", \"\\ubb38\", \"\\uac80\\uc0c9\", \"\\ub9ac\\uc544\\ub178\", \"\\uc6b0\\ud68c\", \"\\ubc1c\\uacac\", \"\\uce58\\uba74\", \"\\ud6c4\\ubcf4\", \"\\ud0dc\\uad6d\", \"\\ud64d\\ucf69\", \"\\ub178\\ud0dc\\uc6b0\", \"\\uc804\\ub450\\ud658\", \"\\uccad\\uc640\\ub300\", \"\\uc0c1\\ud488\", \"\\ubc30\\uc5ed\", \"\\uc18d\\ucd08\\uc2dc\", \"\\ud50c\\ub7ab\\ud3fc\", \"\\uc2dc\\uc7a5\", \"\\uc288\\ud37c\\ub9c8\\ucf13\", \"\\uac00\\uba74\", \"\\uc911\\uad6d\", \"\\uc0c8\\uce58\\uae30\", \"\\ub098\", \"\\uacc4\\uc0b0\", \"\\ud3b8\\uc9d1\\uc7a5\", \"\\ub178\\ub3d9\\uc790\", \"\\uac10\\ub3c5\", \"\\ub450\", \"\\uc791\\ud488\", \"\\ub9cc\\ud654\", \"\\uc0b6\", \"\\ubb34\\ucc99\", \"\\ud22c\\uc7c1\", \"\\uce7c\\ub7fc\", \"\\uc758\\ub8cc\", \"\\ub098\\uc740\", \"\\uc808\\ubc15\", \"\\uac70\\uc6b8\", \"\\uc784\\uae08\", \"\\ubbf8\\uad6d\\uc778\", \"\\uc678\\ub85c\\uc6c0\", \"\\ud45c\\ud604\", \"\\ub9e4\\uc77c\", \"\\uba54\\ub274\", \"\\uc2dc\\uccad\\uc790\", \"\\ud604\\uc2e4\", \"\\ubd80\\ucc44\", \"\\ub9ac\\ubca0\\ub77c\", \"\\ud601\", \"\\uacc4\\ubcf4\", \"\\uc124\\uad6d\\uc5f4\\ucc28\", \"\\ud568\", \"\\ud638\\uc810\", \"\\uc7a1\\uc9c0\", \"\\uc774\\ud574\", \"\\ucf58\\ud150\\ud2b8\", \"\\uc0dd\\uac01\", \"\\uac83\", \"\\uc791\\uc5c5\", \"\\uadf8\", \"\\uc2dc\\ub9ac\\uc988\", \"\\ub54c\", \"\\ud55c\\uad6d\\uc5b4\", \"\\ube48\\uace4\", \"\\uc728\", \"\\uc0c1\\ub300\", \"\\uc885\\ud559\", \"\\uc18c\\ub4dd\", \"\\uad50\\uc721\", \"\\uc911\\uc704\", \"\\uc778\\uad6c\", \"\\uc774\\uc0ac\\uc7a5\", \"\\uc870\\ud615\", \"\\ubc29\\uc774\\ub3d9\", \"\\ub958\\ud6a8\\ub9bc\", \"\\uac00\\uad6c\", \"\\uc7ac\\ub2e8\", \"\\uc138\\uc885\", \"\\uace0\\ub839\\ud654\", \"\\uc5b8\\uc5b4\", \"\\ud559\\ub2f9\", \"\\uc218\\uc900\", \"\\uae30\\uc900\", \"\\uae30\\ub150\", \"\\uc0dd\\ud65c\", \"\\ubb3c\", \"\\uc794\\ub514\", \"\\ub9c8\\ub2f9\", \"\\uc124\\uce58\", \"\\uc1a1\\ud30c\\uad6c\", \"\\ub204\\ub9ac\", \"\\ucf54\\uc2a4\\ud0c0\\ub9ac\\uce74\", \"\\uc220\\ub798\", \"\\ub85c\\ubd07\", \"\\uc2dc\\ubbfc\", \"\\uc62c\\ub9bc\\ud53d\", \"\\uacf5\\uc6d0\", \"\\uc11c\\uc6b8\", \"\\uc624\\ud6c4\", \"\\uc758\\uc0c1\", \"\\uc0ac\\ud0d5\", \"\\uc138\\ube10\\uc77c\\ub808\\ube10\", \"\\uad6c\\uc2ac\", \"\\uac8c\\uc2dc\", \"\\uad11\\uace0\", \"\\uacf5\\uc815\\uc704\", \"\\uad11\\uace0\\uc8fc\", \"\\uc885\\uc790\", \"\\ubc31\\uc2e0\", \"\\uc815\\uad6d\", \"\\ube44\\ud589\\uae30\", \"\\ud3b8\\uc758\\uc810\", \"\\uce94\\ub514\", \"\\ud380\\uc288\\uba38\", \"\\uc81c\\ud488\", \"\\uc637\", \"\\uac1c\\ubc29\", \"\\uc0ac\\uace0\", \"\\uce5c\\ud615\", \"\\uc790\\ubc1c\", \"\\uad00\\uad11\\uc9c0\", \"\\ubbfc\\uc6d0\", \"\\uc791\\uc131\", \"\\uc5c5\\uacc4\", \"\\uad00\\uad11\\uac1d\", \"\\ucd08\\ucf5c\\ub9bf\", \"\\uad6c\\ub450\\uc57d\", \"\\uc2ac\\uce58\", \"\\uae30\\uc6a9\", \"\\ub9e4\\uc9c1\", \"\\ucd9c\\ucc98\", \"\\uc120\\ubc1c\", \"\\uac1c\\uc778\", \"\\ud0c0\\uace0\", \"\\uae30\\uc0ac\", \"\\ud45c\\uc2dc\", \"\\ub274\\uc695\", \"\\ud55c\\uad6d\", \"\\uad00\\uad11\", \"\\ud2b8\\ub808\\uc774\\ub2dd\\ubcf5\", \"\\ud559\\ubd80\\ubaa8\", \"\\ud559\\uc0dd\", \"\\uc751\\ub2f5\", \"\\ud559\\uad50\", \"\\ucc38\\uc5ec\", \"\\uc9c0\\ub3c4\", \"\\ubb34\\uc120\", \"\\uc9d1\\uacc4\", \"\\uc5ec\\ub860\\uc870\\uc0ac\", \"\\uc758\\ud5a5\", \"\\uc11c\\uad6c\", \"\\ubaa8\\ubc29\", \"\\ub370\\uc774\", \"\\uacf5\\uc9c0\", \"\\ucd08\\uad50\", \"\\uc870\\uc9d0\", \"\\uac00\\ub85c\", \"\\ub300\\uc720\\ud589\", \"\\uc785\\uc9c0\", \"\\uc77c\\uc790\", \"\\uc758\\uc0ac\", \"\\uacbd\\ubd81\", \"\\ucf58\\ud150\\ud2b8\", \"\\ubcf5\\uc7a5\", \"\\ub300\\uad6c\", \"\\uc774\\uacbd\\ud76c\", \"\\uc5f0\\uc2b5\", \"\\uac24\\ub7fd\", \"\\ubd88\\ucc38\", \"\\uc2ec\\uc758\", \"\\uc8fc\\ub958\", \"\\uc791\\uc5c5\", \"\\ud57c\\ub7ec\\uc708\", \"\\ud3ed\\ub825\", \"\\uc870\\uc0ac\", \"\\ub180\\uc774\", \"\\ub54c\\ubb38\", \"\\ub85c\", \"\\uae08\\uc9c0\", \"\\ub839\", \"\\uc55e\\uc11c\", \"\\uc2a4\\ud2f8\\ucef7\", \"\\uaddc\\uc815\", \"\\uc138\", \"\\ucc28\\uc9c0\", \"\\ub4dc\\ub77c\\ub9c8\", \"\\uc720\\ucfe0\", \"\\uc131\\uacf5\", \"\\ub85c\\uace0\", \"\\ud32c\\ub370\\ubbf9\", \"\\ubc31\\uc545\\uad00\", \"\\ucde8\\uc7ac\", \"\\uc870\\ud615\", \"\\ubc29\\uc774\\ub3d9\", \"\\ub958\\ud6a8\\ub9bc\", \"\\ud45c\\uc808\", \"\\ud574\\uba85\", \"\\uae30\\ub150\", \"\\uc911\\uad6d\", \"\\uac70\", \"\\ubb3c\", \"\\ube44\\ud310\", \"\\ubbf8\\ub098\\ub9ac\", \"\\uce5c\\uc219\\ub3c4\", \"\\uc870\\uc885\", \"\\ubb34\\uc791\\uc815\", \"\\uac15\\uc778\", \"\\ubb54\\uac00\", \"\\ud558\\uccad\", \"\\uc624\\uc815\\uc2dd\", \"\\ub514\\ub098\", \"\\uc18c\\uc9c0\\ud61c\", \"\\uc6cc\\uc2f1\\ud134\\ud3ec\\uc2a4\\ud2b8\", \"\\ub9c8\\uc77c\", \"\\uc804\\ub77d\", \"\\ud611\\uc0c1\", \"\\uc794\\ub514\", \"\\ub9c8\\ub2f9\", \"\\uc124\\uce58\", \"\\uc1a1\\ud30c\\uad6c\", \"\\ub204\\ub9ac\\uafbc\", \"\\uc774\\ubbf8\\uc9c0\", \"\\uc220\\ub798\", \"\\ub85c\\ubd07\", \"\\uc2b9\\ub9ac\", \"\\uc2dc\\ubbfc\", \"\\uc62c\\ub9bc\\ud53d\", \"\\uac78\", \"\\ucf58\\ud150\\uce20\", \"\\uacf5\\uc6d0\", \"\\uc11c\\uc6b8\", \"\\uc624\\ud6c4\", \"\\ud504\\ub85c\\uadf8\\ub7a8\", \"\\ucd2c\\uc601\", \"\\uba54\\ud0c0\", \"\\ubc84\\uc2a4\", \"\\uacb0\\uc81c\", \"\\uc5f0\\uc218\", \"\\ucf54\\ub9ac\\uc544\", \"\\ucf54\\uc5d1\\uc2a4\", \"\\ud658\\ubd88\", \"\\uac15\\ub0a8\\uad6c\", \"\\uc9c4\", \"\\uc2e0\\uc6a9\\uce74\\ub4dc\", \"\\ud574\\uc9c0\", \"\\uad6c\\ub3c5\", \"\\uc720\\ub8cc\", \"\\uc18c\\ube44\\uc790\", \"\\ud50c\\ub7ab\\ud3fc\", \"\\uc815\\uae30\", \"\\uace0\\uc9c0\", \"\\uc18c\\uc544\", \"\\ubd88\\ubc95\", \"\\uc774\\uc6a9\", \"\\uc18c\\ud0d5\", \"\\uc8fc\\uc911\", \"\\uae30\\uc900\", \"\\ud68c\\ucc28\", \"\\uc2dc\\ud589\", \"\\uce68\\ud574\", \"\\uc804\\ud658\", \"\\uc791\\uc804\", \"\\uc9c0\\uc801\\uc7ac\\uc0b0\\uad8c\", \"\\uc5ec\\ubd80\", \"\\ubcf4\\ud638\", \"\\uc5c5\\uccb4\", \"\\uad00\\ub828\", \"\\uc720\\ud1b5\", \"\\ubcf5\\uc7a5\", \"\\uc911\\uad6d\", \"\\uccad\\uc18c\\ub144\", \"\\uc11c\\uc6b8\", \"\\uc784\\ub300\\ub8cc\", \"\\uc81c\\uae30\\ucc28\\uae30\", \"\\ucfe1\", \"\\ubc15\\uc2a4\", \"\\ud0a4\\ud2b8\", \"\\uc5f0\\uccb4\", \"\\ubc95\", \"\\uad6c\\uc2ac\", \"\\uac74\\uad6d\", \"\\uc131\\uc2e0\", \"\\ud55c\\uc885\", \"\\uc190\\uc2e4\", \"\\uc190\\uc2e4\\ubcf4\\uc0c1\", \"\\ubcf4\\uc0c1\\uae08\", \"\\ubd84\\ub2f4\", \"\\ud2c0\", \"\\uc18c\", \"\\uc124\\ud0d5\", \"\\uc6b4\\ub3d9\\uc7a5\", \"\\uc0c1\\uc778\", \"\\uc790\\uc601\", \"\\ucc2c\", \"\\uc11c\\ub85c\", \"\\uac15\\uc81c\", \"\\uc784\\ub300\", \"\\ud1f4\\uac70\", \"\\uc544\\uc2dc\\uc544\", \"\\ub3c5\\uc77c\", \"\\ud14c\\ub9c8\", \"\\ub300\\ud559\\uad50\", \"\\ub9b0\\ub2e4\", \"\\uc5c5\\uc790\", \"\\uc5b4\\uac00\", \"\\uc11c\\uc6b8\", \"\\uae00\\ub85c\\ubc8c\", \"\\uc9c1\\uc811\", \"\\uc624\\ud6c4\", \"\\uc608\\ub2a5\", \"\\uc81c\\ud398\\ud1a0\", \"\\uc720\\ud050\", \"\\uba54\\ud0c0\", \"\\uc8fc\\uc81c\", \"\\uc774\\uc6a9\\uc790\", \"\\uc6b0\\uac04\\ub2e4\", \"\\ub85c\\uace0\", \"\\ubc84\\uc2a4\", \"\\ub85c\\ube14\\ub85d\\uc2a4\", \"\\ub77c\\uc774\\ube0c\", \"\\uc720\\ud29c\\ubc84\", \"\\ucd9c\\uc5f0\\uc790\", \"\\ub7a9\\uc18c\\ub514\", \"\\ubcf4\\ud5e4\\ubbf8\\uc548\", \"\\ub77c\\ubbf8\", \"\\ub9d0\\ub809\", \"\\ubba4\\uc9c1\\ube44\\ub514\\uc624\", \"\\uc774\\uc790\", \"\\uc2b9\\ub9ac\", \"\\ubbf8\\uc0ac\", \"\\uc0c8\\ud130\\ub370\\uc774\", \"\\uc544\\uc774\\ud15c\", \"\\ud504\\ub85c\\uadf8\\ub7a8\", \"\\uacf5\\uac04\", \"\\uc218\\uc815\", \"\\ud328\\ub7ec\\ub514\", \"\\ud65c\\ub3d9\", \"\\uc911\\uc778\", \"\\uccb4\\uc721\\ubcf5\", \"\\uacf5\\uac1c\", \"\\ub098\\uc774\\ud2b8\", \"\\ub85c\", \"\\uc601\\ud654\", \"\\uc778\\ubb3c\", \"\\uce90\\ub9ad\\ud130\", \"\\uc81c\\uc791\", \"\\ud604\\uc9c0\", \"\\uacb0\\uc81c\", \"\\ud560\\ub85c\\uc708\\ub370\\uc774\", \"\\uacf5\\uc6d0\", \"\\uc601\\ud76c\", \"\\ubb34\\uc0c1\", \"\\uc138\\uad00\", \"\\uc62c\\ub9bc\\ud53d\", \"\\ub2e8\\uc18d\", \"\\ud574\\uc9c0\", \"\\ud2b9\\uc218\", \"\\ud2b8\\ub808\\uc774\\ub2dd\\ubcf5\", \"\\uc2e0\\uc6a9\\uce74\\ub4dc\", \"\\uc801\\ubc1c\", \"\\ud658\\ubd88\", \"\\uc6d0\\uc0b0\\uc9c0\", \"\\uc74c\\uc131\", \"\\uc720\\ub8cc\", \"\\ubcf8\\ubd80\", \"\\ubd80\\ud569\", \"\\uc6b0\\ub69d\", \"\\uc790\\ub791\", \"\\ub3cc\\ud30c\", \"\\uc911\\uc21c\", \"\\ub300\\uad00\", \"\\uc2a4\\ud53c\\ucee4\", \"\\ub9cc\\ub0a8\", \"\\ud5c8\\uc704\", \"\\uc18c\\ube44\\uc790\", \"\\uace0\\uc9c0\", \"\\ub178\\ub9ac\", \"\\uc815\\uae30\", \"\\ub3d9\\uc0c1\", \"\\uac00\\uba74\", \"\\uae30\\uc900\", \"\\ud45c\\uc2dc\", \"\\uad6c\\ub3c5\", \"\\ucee4\\ubba4\\ub2c8\\ud2f0\", \"\\ud310\\ub9e4\", \"\\uc804\\uc2dc\", \"\\ub85c\\ubd07\", \"\\uacbd\\uc81c\", \"\\ud64d\\ubcf4\", \"\\uc628\\ub77c\\uc778\", \"\\uc1fc\\ud551\\ubab0\", \"\\uace0\\uc12c\", \"\\uc5b4\\uc6cc\\uc988\", \"\\uc904\\ub9ac\\uc544\", \"\\ub178\", \"\\ubd80\\ubb38\", \"\\ub3c5\\ub9bd\\uc601\\ud654\", \"\\uc2dc\\uc0c1\\uc2dd\", \"\\ud6c4\\ubcf4\", \"\\ud654\\uc774\\ud2b8\", \"\\ubc84\\ub4dc\", \"\\ub85c\\ub4dc\", \"\\uc5f0\\uae30\\uc0c1\", \"\\ub85c\\ud22c\\uc2a4\", \"\\ucd5c\\uc6b0\\uc218\", \"\\ud658\\ubd88\", \"\\ub354\", \"\\uacb0\\uc81c\", \"\\uc190\\ub2d8\", \"\\uc0c8\", \"\\uc561\\uc2a4\", \"\\ucfe8\\ub9ac\\uc9c0\", \"\\ud2b8\\ub864\", \"\\uc81c\\ub2c8\\ud37c\", \"\\uac2c\\ube57\", \"\\ub808\\uc77c\\ub85c\\ub4dc\", \"\\ud6c4\\uc6d0\", \"\\ud2f0\\ube0c\\uc774\", \"\\ud638\\ud06c\", \"\\uc2a4\\ubab0\", \"\\ud14c\\uc77c\\ub7ec\", \"\\uc774\\uc815\\uc7ac\", \"\\uad7f\", \"\\uc81c\\ubcf4\\uc790\", \"\\uad6c\\ub3c5\", \"\\uae30\\uc900\", \"\\uc758\\ud639\", \"\\uc2e0\\uc6a9\\uce74\\ub4dc\", \"\\ub9b0\\ub2e4\", \"\\ud574\\uc9c0\", \"\\uc2dc\\ub9ac\\uc988\", \"\\uc804\\ud658\", \"\\uacc4\\uc0b0\", \"\\uc8fc\\uc911\", \"\\ubd88\\ubc95\", \"\\uc791\\uc804\", \"\\uc774\\uc0ac\\uc7a5\", \"\\ubcf8\\ud1a0\", \"\\uc9c0\\uc801\\uc7ac\\uc0b0\\uad8c\", \"\\uc2dc\\ub9ac\\uc544\", \"\\ub300\\uc0ac\\ub3c4\", \"\\uce68\\ud574\", \"\\uc7a5\\ud558\", \"\\uc720\\ud1b5\", \"\\uc18c\\uc9c0\", \"\\uc885\\ud559\", \"\\ub2e4\\uc218\", \"\\uad6d\\uc815\\uac10\\uc0ac\", \"\\uad50\\uc721\", \"\\ub300\\uc0ac\\uad00\", \"\\ub3cc\\uc785\", \"\\uc0c1\\ud45c\\uad8c\", \"\\ud559\\ub2f9\", \"\\ud55c\\uad6d\\uc5b4\", \"\\uc18c\\ud0d5\", \"\\uc5ec\\uac1c\", \"\\uad7f\", \"\\uad11\\uc800\\uc6b0\", \"\\uad7f\\uc988\", \"\\uc6b0\\uc120\", \"\\uc790\\ucde8\", \"\\uad50\\uc6d0\", \"\\uc5b8\\uc5b4\", \"\\uc5c5\\uccb4\", \"\\ucd9c\\uc6d0\", \"\\uc0c1\\ud45c\", \"\\uc774\\uc720\", \"\\ubc15\\uc131\\uc6b0\", \"\\uc1fc\\ud551\\ubab0\", \"\\uc911\\uad6d\", \"\\ud310\\ub9e4\", \"\\uc628\\ub77c\\uc778\", \"\\uc9c4\", \"\\ubcf4\\ub3c4\", \"\\uc0c1\\ud488\", \"\\ub9e4\\uccb4\"], \"Freq\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21994455595756773, 0.12368198508241285, 0.10645116614604865, 0.09305907356392916, 0.0930489472345769, 0.07475455002015338, 0.07474145183327384, 0.09634624517486778, 0.07322263451299203, 0.08186213804090467, 0.06439825943312233, 0.06438787994553626, 0.0825396335020896, 0.06439609658125524, 0.09319839864756055, 0.07042575885621821, 0.06001295344520981, 0.055729708749600336, 0.056055754540983556, 0.06752768594720021, 0.05108304990592187, 0.06188463481933871, 0.05949681884087715, 0.06481767108182132, 0.05323959483092153, 0.043029712254628566, 0.04302569749524678, 0.043023757532694246, 0.04302249724496508, 0.04302243395540663, 0.05455599012951562, 0.050717797608937853, 0.06512812012462613, 0.04482455735307728, 0.05561088948290727, 0.1012563371745813, 0.07845477680674652, 0.07381613647495187, 0.07660933033045578, 0.07304440925548442, 0.073044367073928, 0.09754796010346695, 0.08308106242580768, 0.08307586354897932, 0.08306830250499161, 0.07485323348505195, 0.0748447760829904, 0.06787366225255821, 0.05235411328913042, 0.06901671388642235, 0.06449199323810197, 0.06291460339050936, 0.06447127154851226, 0.08770816825694056, 0.04560060883555758, 0.04559679667739642, 0.048888286796928256, 0.04885378228377937, 0.059835824314597975, 0.04559831521342742, 0.04865500697186009, 0.05496652253190937, 0.04165191688531676, 0.04434852842374532, 0.03711511913012483, 0.03711147042549478, 0.03711062415801917, 0.03711053188586451, 0.03711052924951723, 0.04606937774471122, 0.0425185606890239, 0.06316638510076081, 0.044571099406178184, 0.1206471920298347, 0.07589278739755309, 0.07812829388835947, 0.05043270648548664, 0.06780270232927618, 0.07594863577824883, 0.06145971405544548, 0.057118024453111836, 0.05043129867604123, 0.051004925661752305, 0.04934330451869004, 0.12288077985923473, 0.11220346063354064, 0.08351610250887566, 0.08047576284505753, 0.09756834681152038, 0.07777101323763778, 0.1017036839260743, 0.06407797055848931, 0.06263148518425976, 0.08295203207031941, 0.05722747475214123, 0.05722400015665091, 0.05721811441732245, 0.05721062124876856, 0.057209136337014584, 0.05720900891884428, 0.057208778585997946, 0.05720731817773826, 0.05720720546166453, 0.057207136851880516, 0.05720648995963126, 0.05720565194012654, 0.05698319941756403, 0.05696923242581872, 0.05221781865642742, 0.05058811085399368, 0.055608911138910595, 0.04929270422415867, 0.049282608784511184, 0.04947957767301207, 0.07343822206539602, 0.07133082844317608, 0.06462954421495765, 0.07925490564625047, 0.05742806035639933, 0.07537749173377048, 0.058992300312936945, 0.05898976728472285, 0.058978479095909773, 0.059840314923653895, 0.06321003196368351, 0.0509722395400676, 0.05217398049706744, 0.08717925554187643, 0.05098558610802311, 0.04745036222635364, 0.04704992289222646, 0.05130730418869156, 0.051305076627701805, 0.04546137583829625, 0.05148476654754228, 0.051499151704060525, 0.042622852202896, 0.0426205494499741, 0.042612480415755924, 0.046571114766822484, 0.052610822125343695, 0.04181060545440067, 0.05757943450896479, 0.05692780712651998, 0.04041026380662621, 0.03924954239835865, 0.03997849293427389, 0.043218823457067186, 0.037489928999305706, 0.05087042026495347, 0.055226584962272396, 0.04295789805353693, 0.049708310155689134, 0.04567983659814833, 0.04769930861519424, 0.04475862734098522, 0.04565545091465497, 0.11082347829466373, 0.11062515755282257, 0.09831017749803649, 0.0837283171999908, 0.0708993524137726, 0.0601011896667164, 0.06478702718364945, 0.04956068794015868, 0.05572069845608751, 0.046618475433154394, 0.04510430554503764, 0.045585492192735166, 0.0742439999014893, 0.04143843629984351, 0.041438050973358724, 0.045807993304809946, 0.043043928564854984, 0.040465872252239014, 0.039509247121346444, 0.03950866233174012, 0.03950808207538656, 0.03950610557718223, 0.0404631749668455, 0.05813384863297257, 0.04046488853638961, 0.05086426103795422, 0.034516009734607944, 0.03687010749438608, 0.033305234587481226, 0.03852695471331424, 0.04735131200818771, 0.04037275470725046, 0.057686262454748546, 0.04175868340797706, 0.0532642013162902, 0.04444002081827446, 0.04118094754294999, 0.041306137851231176, 0.1190751306165079, 0.10240032467827831, 0.06161057200665406, 0.08397066982525406, 0.04899113115816393, 0.04443195049437502, 0.042868204337679475, 0.042867419672754654, 0.04286656564518455, 0.050983070264883676, 0.078581209627037, 0.05151858456782976, 0.05881656228631174, 0.057623598485168584, 0.05750636694430119, 0.0373213559621386, 0.034369004328099736, 0.03436729193779419, 0.034367229077896896, 0.03436481872597314, 0.03436413376985092, 0.034363095497754265, 0.03436277903068514, 0.036946034688485174, 0.04051795514606319, 0.037037298589022875, 0.03428457048054024, 0.03731438501628715, 0.03293174745783488, 0.04435474553500413, 0.04926797915133503, 0.048507534795215926, 0.047387440788113154, 0.05096292041642751, 0.045942378452670726, 0.04698955497891448, 0.04136256240190863, 0.0462809505298175, 0.04576446326750699, 0.056827683806315324, 0.0525335811618252, 0.04546449150246299, 0.044363420200830464, 0.047145872370401666, 0.0531539086392972, 0.046489905498747625, 0.04448147975827599, 0.04390907319836734, 0.11149676676657509, 0.06363965883340654, 0.07752013959445635, 0.05592559341971636, 0.10798609249326682, 0.07478113213707376, 0.03790270994575166, 0.057042892820992806, 0.03254872272916809, 0.06423402112379041, 0.03329578801604228, 0.06923182948152706, 0.02881542351576648, 0.039942171550168167, 0.04796878547478809, 0.029832145698718355, 0.02935063562142671, 0.047606625884585696, 0.034214954484805, 0.03495491376088734, 0.03658264979290546, 0.09907811418751453, 0.0334526335011447, 0.03060094777653695, 0.030600544050326955, 0.028684654878365894, 0.026626531674136412, 0.0266277858023632, 0.030596435921392294, 0.026631799442184884, 0.04026881611877023, 0.04936209616498993, 0.0700126617414115, 0.04173908819149189, 0.03511124385082807, 0.04275395280438183, 0.03529106737022265, 0.04138443619081149, 0.0367420486315381, 0.03333552068804914, 0.034468357105970786, 0.03546751719878797, 0.11725953740890743, 0.10548698179232396, 0.06658613981282643, 0.045091860942602806, 0.05995261905621691, 0.04783473285232074, 0.04177888302705254, 0.03550426700219593, 0.04273773834289776, 0.061826471659463714, 0.05713180060449382, 0.07595755099384269, 0.03473740441755544, 0.03325873554284848, 0.031625213408735, 0.03267389667329847, 0.04983449693016853, 0.05116977278291425, 0.027454305633990084, 0.05817942389281389, 0.026914944984708235, 0.03535370201169807, 0.03594671237110927, 0.028441294653892547, 0.029403992887411086, 0.049353880325509025, 0.03362418552714618, 0.06133063653657197, 0.05786269251243338, 0.04486348241092121, 0.0537304255066375, 0.03880225209787757, 0.032810258788200354, 0.033963734609055246, 0.036589827767242705, 0.03390067206806483, 0.03320908391801743, 0.11016520773100977, 0.10319109981404992, 0.07498218222465429, 0.07450624857899893, 0.07546193340187023, 0.07825334337227816, 0.05539934497397404, 0.04861778334537845, 0.04518840794900299, 0.042793263639023964, 0.04128094740797125, 0.048690798233694446, 0.03630375420814021, 0.03626782969148929, 0.037083126446219854, 0.03495171545821433, 0.04006252226266534, 0.08276398861098426, 0.0300513841004684, 0.030047401068984684, 0.030047204307964943, 0.03558794865165294, 0.05428969005593581, 0.032568130398423045, 0.028099698673447405, 0.028096868624761608, 0.02809198453814076, 0.05639648568870541, 0.029243076959158707, 0.026702877483206225, 0.03875407619249614, 0.03166562253974662, 0.032926614265285724, 0.03549308409570559, 0.0436482914086378, 0.03359939719730714, 0.03388012920027577, 0.03355946022696395, 0.03994678982792323, 0.031301603191655154, 0.04209880418393239, 0.03501243838522492, 0.0421462155487017, 0.027620155644475283, 0.028075702924203378, 0.02670071520486628, 0.024424664896009696, 0.026079776083579122, 0.02698960034968716, 0.024075797591635813, 0.023649021311041234, 0.023628522194389767, 0.022920877183307285, 0.03734421070201756, 0.022604163628730505, 0.02257959816388552, 0.022278616161743717, 0.022392965467118026, 0.026845574454637106, 0.02597356476013976, 0.020902215439264852, 0.02166597006513025, 0.0218495935232866, 0.02047084954123348, 0.020415575043020637, 0.019799058163486392, 0.020263791725485286, 0.020413941808715873, 0.021738012083168796, 0.0213226895848992, 0.024882088545246494, 0.026947959041388286, 0.02118694790527632, 0.022869593273767887, 0.021741727823350827, 0.02156614896911632, 0.08825713806161292, 0.1038586669994746, 0.09603655061614298, 0.08111109180812956, 0.048029228113432666, 0.051107828109823096, 0.037936655739264795, 0.04330522606122503, 0.04087971087613343, 0.035959672641271825, 0.05179222790870906, 0.05180000042082319, 0.051798387780286594, 0.03697086400915192, 0.03412643256896199, 0.0307239825152858, 0.03324369874768752, 0.02970049908906672, 0.027305644837782393, 0.03963555524155227, 0.04065221782120993, 0.04462697185346903, 0.029292442203075295, 0.04207934932645989, 0.04207965385943676, 0.042064890931262734, 0.04206531312470794, 0.042076227863447, 0.02528463250041811, 0.025129819008905475, 0.0399100363505655, 0.042075639561105334, 0.04207187788672062, 0.04207630745729323, 0.04207089853635183, 0.042355072791594665, 0.03491654337744283, 0.035224204738526506, 0.06497446335432161, 0.05038162686959405, 0.07004654974165186, 0.04060686536215321, 0.05082109035069839, 0.03993966318750388, 0.03993600313496075, 0.03161629912277769, 0.03161362072957132, 0.03450730155099862, 0.03353565953028087, 0.028519261140342086, 0.028517266458750457, 0.02850870124581533, 0.04565364501086262, 0.030318855972468584, 0.02753917308577802, 0.02494640848656977, 0.023293530953495543, 0.023291326140352592, 0.023288879832740216, 0.023285751381659003, 0.023285196258008505, 0.028420342496631383, 0.02398538751806909, 0.02122471526418932, 0.021223940600112068, 0.021223764967770665, 0.0212231314368249, 0.021222504178462748, 0.02514976407943217, 0.022111973785593233, 0.02468588299843532, 0.023823478021485604, 0.025704857935160738, 0.025893106010370807, 0.03617366670700493, 0.03284433927160696, 0.02821315905961398, 0.024164901020586254, 0.03882584653766517, 0.05138221050429543, 0.0283341437757469, 0.05964347725567761, 0.03963487730465171, 0.024589805622507736, 0.024367872086397183, 0.023368715740813402, 0.02326008714636007, 0.023134237222306994, 0.020630622231286238, 0.022483468743412584, 0.022486726295955096, 0.01716810493681416, 0.017167615452655986, 0.01716740121466212, 0.0171668251840296, 0.01716574831888162, 0.017163744980819764, 0.01716348676019139, 0.02205381373731445, 0.016338056145714045, 0.018010256046375784, 0.02659782854433773, 0.015930493191288145, 0.017609650860969255, 0.017304346112967127, 0.015554437409907347, 0.015497830340507902, 0.015497556513138257, 0.017569571330580142, 0.01858938532643351, 0.026665720706473734, 0.0338114998816022, 0.020249826256941793, 0.021613500745720087, 0.020065709273735466, 0.020144621214006352, 0.02182112857526002, 0.01916851460649123, 0.018457245885646567, 0.018229532180085585, 0.018090456252199197, 0.018203149693357363, 0.018298681394291565, 0.018971659684815102, 0.07086976344143502, 0.03767250917396198, 0.039882201340691883, 0.03122343800926131, 0.03121975051923623, 0.027089616767961795, 0.040807020618465764, 0.04082286287000726, 0.04081626886491876, 0.031128223474246996, 0.022148076869167997, 0.035167289103963266, 0.046815611169748854, 0.024028788029890676, 0.033144043303333884, 0.02573996321363074, 0.01856698327662363, 0.018566477387344352, 0.018566470677937465, 0.018566348566732123, 0.018566255976917082, 0.018565477685718194, 0.018565415959174835, 0.01856503754862641, 0.018564946300692747, 0.018564902018607294, 0.01856477453987644, 0.01856469805263793, 0.01856465645431523, 0.018564588018364983, 0.03314006865069405, 0.033134456902773786, 0.03313469575765896, 0.03312512545967539, 0.019495680591578177, 0.023968432889298282, 0.031421472862937, 0.03313829736727589, 0.027907047962865653, 0.033139604359737465, 0.03314518390250467, 0.021630295837124305, 0.030047246776823116, 0.033137661315503004, 0.032808554172646304, 0.027480724197979572, 0.028964576625100966, 0.026384439317802388, 0.07150641735900307, 0.06646594598073371, 0.054814886792044826, 0.04120057970522847, 0.04120054478592761, 0.035363816072951575, 0.038359121367521606, 0.03535704422282133, 0.03536275103427547, 0.030127669403865385, 0.030133533352173378, 0.027314258747453028, 0.026786865063921084, 0.02818308337780954, 0.03247637899296077, 0.021902495431655872, 0.021904201488926255, 0.030167786692077106, 0.025268234646646966, 0.02584999019890401, 0.02494539323905654, 0.018716702856681863, 0.029174123066925458, 0.020020836479977894, 0.020022960321740658, 0.02905178579061306, 0.023769131601258545, 0.0227910793978252, 0.022346182562564997, 0.020742292930897865, 0.023223889166517752, 0.032987627488318474, 0.027327607897323032, 0.02496039856148142, 0.02519165163139872, 0.02931011877834401, 0.02532187069276142, 0.027784659143516813, 0.07392231012385715, 0.04211398761557884, 0.03306344325949122, 0.03221705581623926, 0.031068731745950432, 0.028129990109455667, 0.0320556329906923, 0.039065974926832996, 0.036094006353286474, 0.036090307695862134, 0.03608948915975491, 0.02355394875707073, 0.023551401679098104, 0.023550850515816735, 0.02354871153320989, 0.02372002011718652, 0.023669338894432845, 0.023288159059789044, 0.03257134357350356, 0.021259273077427684, 0.022207372427161136, 0.032568826985414585, 0.026555846669483442, 0.018972107290665254, 0.01897078449878997, 0.018970109030598332, 0.021562436335937553, 0.020035509998861202, 0.030073009543330993, 0.02813954282454085, 0.02814116816987697, 0.020659093790026967, 0.024055247006418097, 0.0280789899156115, 0.022123128878635562, 0.0222431065707992, 0.02212209456796712, 0.04346022747221338, 0.0246058570436916, 0.023691366114452578, 0.03191759045624705, 0.023518750709032015, 0.022411990756036382, 0.023681709580266067, 0.02370563035820595, 0.028555358955841614, 0.018958774133462038, 0.017399161581812924, 0.017396136629624557, 0.017387437749360926, 0.017376652143484918, 0.01737559392447229, 0.01736818524859878, 0.017354558678937253, 0.017313491553194487, 0.017164992341967757, 0.026003844354331, 0.017375855622262668, 0.01731367668438244, 0.015229598905109717, 0.031155835042640603, 0.01646631866647909, 0.015332727261866295, 0.02290792978172347, 0.014908540284932856, 0.014949578841047851, 0.014543478724063509, 0.020174993472728244, 0.015924403110213117, 0.017815862173485318, 0.01873678355454298, 0.017409162094317792, 0.016445220567762958, 0.01741716730401915, 0.017001194666462355, 0.026124488263872005, 0.02059393852961464, 0.04122221317954333, 0.038698741836651916, 0.015557302972838985, 0.01812054552560125, 0.031014243920236054, 0.017491656645399534, 0.014157331876145138, 0.012531674564510658, 0.0155209614005282, 0.01372508410554075, 0.01822061774584132, 0.01429796854449424, 0.013888364496331938, 0.012510110573449147, 0.012426347761953789, 0.011310785694242062, 0.009669566671283616, 0.009669435844935357, 0.00966900610522177, 0.009668553181092037, 0.009668465411516622, 0.009668269171994233, 0.009667951214287072, 0.0096669683606454, 0.009987933417787666, 0.013188378947985014, 0.010689454933704344, 0.009592723579993344, 0.010505403790089827, 0.016874022143207573, 0.014634632763427632, 0.013919838997281529, 0.01245354639415394, 0.01123573608314375, 0.011094453563201974, 0.01436036774452479, 0.011711520875213188, 0.013993191177911916, 0.011540703893144426, 0.011094272227947108, 0.011531551016855445, 0.011277559941858492, 0.02625702648683029, 0.02625306458589945, 0.030206290118966635, 0.027321484393099033, 0.02251556018877287, 0.020527242335518604, 0.020337257533234992, 0.020333921962230717, 0.01481549794267326, 0.014815183321128751, 0.014815097382836501, 0.014814806066591586, 0.014813026124335157, 0.01480830388800509, 0.014377166041599816, 0.014707579839744587, 0.014024068904044756, 0.010470209539421828, 0.009095008236155574, 0.009094802129912297, 0.009094762073928621, 0.00909461204606249, 0.009094598208540857, 0.00909458946905351, 0.00909430907716778, 0.009094305435714718, 0.009094288685030635, 0.009094049077419192, 0.009093867733056734, 0.009093670366300804, 0.014033609511065715, 0.01108171074083179, 0.01296301939784152, 0.010267411920396255, 0.011721432475177257, 0.010234449487284148, 0.00979614453296336, 0.01047921630942398, 0.009409915270583533, 0.009853870303474444, 0.009520282614841327, 0.009268320281452101, 0.002232653408424329, 0.0027607897134910124, 0.002390790166291123, 0.0020107643580403152, 0.0016734349032292751, 0.0022250518245841068, 0.0016622015760431594, 0.001650009757720841, 0.0027402079671977678, 0.001635194995341522, 0.0026805392028125073, 0.0019273571755451474, 0.0019521617310568403, 0.0020649323982542757, 0.0015715125630538034, 0.0017313768237969512, 0.0015010385301528124, 0.0015993945934867652, 0.001786275650342468, 0.0015883719454204337, 0.0022951275663024404, 0.0019655498508877977, 0.0015994604993636529, 0.0017755502377808997, 0.0015416602764312854, 0.001539610933189464, 0.0014695172870412426, 0.0015344524802054674, 0.0014659463967883416, 0.0016315752248965958, 0.0030615527204716046, 0.001903627984258005, 0.0018313257223321504, 0.0016939553570570144, 0.001746365248161869, 0.0020066125074826493, 0.0024155057488690172, 0.0020521743386063642, 0.0019075807990674698, 0.0017126237459010826, 0.0017489083362647072, 0.0018372368204302037, 0.0017474486309347738], \"Total\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4514309362417762, 0.25566706730427075, 0.2384362483679065, 0.22504415578578701, 0.22503402945643478, 0.20673963224201125, 0.2067265340551317, 0.26739855403423296, 0.20960065229096764, 0.23565641377876384, 0.19865263624755658, 0.20348899787401598, 0.26361557409253983, 0.20706221839427044, 0.3081748342508349, 0.24440898038532194, 0.21010049813456166, 0.20219273102413945, 0.20376812922152637, 0.2465726387142645, 0.18805169838640665, 0.23620809545541394, 0.2273416128504138, 0.2477024674765833, 0.21170584605317908, 0.17501479447648643, 0.17501077971710466, 0.17500883975455211, 0.17500757946682294, 0.17500751617726448, 0.23131546817242474, 0.21622901448527576, 0.3084606657962819, 0.18530541707644152, 0.2523840666253115, 0.6181250862476696, 0.426618211751864, 0.41922789530729165, 0.5745137458410114, 0.20537850155771226, 0.20538003984796413, 0.275861706246891, 0.24626573660294743, 0.24626505491965062, 0.2462537952182386, 0.24268772179641734, 0.2546309729963265, 0.23719629177454185, 0.18468680053706452, 0.25140717800839085, 0.2386281748935237, 0.236196776782833, 0.24707095065544196, 0.3387114149660212, 0.1830143734856124, 0.18302463259760446, 0.19989932264523816, 0.19998415103150485, 0.24501688201622426, 0.18699837835277, 0.19977240369774463, 0.2388607377983515, 0.18603983611113184, 0.20031811839390745, 0.16944166105112543, 0.16943801234649536, 0.16943716607901976, 0.1694370738068651, 0.16943707117051782, 0.21054286729949442, 0.19448440618217216, 0.29198284648846995, 0.20520386199755325, 0.6181250862476696, 0.3718743849655989, 0.41922789530729165, 0.2456029062944542, 0.40842594599359816, 0.5745137458410114, 0.426618211751864, 0.3504743677107216, 0.3036487437244544, 0.3294095367974218, 0.31438558517212717, 0.2563533575916993, 0.2537006391063847, 0.2205427728733922, 0.21394834057752204, 0.26361010315166855, 0.2112435909701023, 0.30622668058178176, 0.19755055158624768, 0.19610406291672428, 0.26276565560946974, 0.19070005248460575, 0.19069657788911543, 0.19069069214978698, 0.1906831989812331, 0.19068171406947912, 0.1906815866513088, 0.19068135631846247, 0.1906798959102028, 0.19067978319412907, 0.19067971458434504, 0.1906790676920958, 0.19067822967259107, 0.19045577715002857, 0.19044181015828326, 0.18569039638889195, 0.18406068858645822, 0.21020876181358755, 0.18769123273874397, 0.1907799519936378, 0.19251068422218998, 0.35592841747617204, 0.34942669824230405, 0.3332312929552701, 0.6181250862476696, 0.5745137458410114, 0.20880565413166013, 0.19242046271082658, 0.19241792968261248, 0.1924066414937994, 0.1981184737165526, 0.2226323863217352, 0.18631681601662814, 0.19271159664906581, 0.33512603225596715, 0.19801270044020716, 0.18443884539869998, 0.18433596205417324, 0.2033931225759576, 0.2051199685407958, 0.1839694075883368, 0.2109023071799203, 0.21164847130232806, 0.17605101460078565, 0.17604871184786375, 0.17604064281364556, 0.20060524468160015, 0.2271542904136798, 0.18185708801928208, 0.25183523605480723, 0.2550888990127749, 0.18142511195523153, 0.17746339591801324, 0.18356840040177438, 0.19991701252800717, 0.17706746844529106, 0.25019777385839526, 0.3720284407765462, 0.217016593111681, 0.33072825895789837, 0.2724959729963153, 0.37404194243962147, 0.2804288927415322, 0.3951151414592858, 0.24517868998617062, 0.24498036924432945, 0.23266538918954338, 0.2316736036309229, 0.2199421882388439, 0.20132277618076716, 0.21821184468902688, 0.18391589963166557, 0.21277467907357944, 0.18097368712466128, 0.17945951723654452, 0.1875625674112822, 0.31438558517212717, 0.1757936479913504, 0.1757932626648656, 0.19508695250762959, 0.1842687119857545, 0.17704197560965468, 0.17386445881285334, 0.17386387402324702, 0.17386329376689347, 0.17386131726868914, 0.17825219193600406, 0.2657821839770978, 0.19024022969015236, 0.24151537111788696, 0.1707867911695462, 0.1826513006624062, 0.16766044627898813, 0.1968303441438611, 0.24501688201622426, 0.21516451009088455, 0.3951151414592858, 0.230392931931869, 0.37404194243962147, 0.33512603225596715, 0.3084606657962819, 0.32726017596958035, 0.26473051491653365, 0.23683018263025035, 0.1960404299586261, 0.3387114149660212, 0.20074296135498745, 0.18269346860660754, 0.1772980622896515, 0.1772972776247267, 0.17729642359715658, 0.21152837878834643, 0.33102494294561186, 0.21973942335267133, 0.2740273885489378, 0.27438028822648813, 0.27440110533027745, 0.18317679656876268, 0.1687988622800718, 0.16879714988976624, 0.16879708702986895, 0.16879467667794518, 0.16879399172182297, 0.1687929534497263, 0.16879263698265717, 0.18275097153179182, 0.2033233491472321, 0.18723367946832403, 0.1735121146220054, 0.18942951230383764, 0.17079592097888832, 0.236196776782833, 0.27415045014971146, 0.275861706246891, 0.27051180673763586, 0.30220108136944457, 0.271288403030524, 0.2816777759162141, 0.23099881880341064, 0.27961721370881437, 0.27860641337454006, 0.40842594599359816, 0.35592841747617204, 0.27865579181026473, 0.2657821839770978, 0.3332312929552701, 0.5745137458410114, 0.3580738778422138, 0.29124685103343, 0.3964263537664563, 0.3773115609382819, 0.22050237510951223, 0.2826092903664558, 0.20562616736473707, 0.426618211751864, 0.33042450927171907, 0.17153756945573442, 0.2692642574604331, 0.16618358223915086, 0.3294095367974218, 0.19021067833161392, 0.3964263537664563, 0.16646247149448393, 0.23099881880341064, 0.2776241123905673, 0.17462255915508632, 0.1744463538257968, 0.28390049654272437, 0.2096935016207797, 0.21422858135053013, 0.22776008486222551, 0.6181250862476696, 0.2112964182040448, 0.19354990672965394, 0.19391920443561209, 0.1826611711442945, 0.17155527156081257, 0.17755768694495783, 0.20423451262678483, 0.1787209201765576, 0.27420951170124475, 0.3580738778422138, 0.5745137458410114, 0.3085891082474834, 0.2465726387142645, 0.35592841747617204, 0.2542939144997793, 0.3718743849655989, 0.3013933605038587, 0.2490573165636017, 0.29124685103343, 0.3749113297462049, 0.2525158232890623, 0.3773115609382819, 0.2826092903664558, 0.19692446462012808, 0.2679886632308962, 0.21516451009088455, 0.19622571052412818, 0.1705991354126682, 0.2092319931667802, 0.30668496060671613, 0.2841569243925553, 0.3951151414592858, 0.18554098314883694, 0.18756288628579829, 0.18377753344868278, 0.18989379593817005, 0.29107106639223096, 0.3003506525728703, 0.16253572545196193, 0.34942669824230405, 0.16198162020609597, 0.21389994582811556, 0.21792347531319273, 0.1750064718048835, 0.1823055029883508, 0.31250253269829237, 0.21633104385988508, 0.3964263537664563, 0.37404194243962147, 0.29080608774926714, 0.3580738778422138, 0.260159551070149, 0.21573560830240138, 0.24639560476236236, 0.3504743677107216, 0.2854077240785256, 0.3720284407765462, 0.24588014677041176, 0.2389060388534519, 0.2106971212640563, 0.21022118761840092, 0.22035382536666814, 0.23194538672492176, 0.19111428401337605, 0.18433272238478046, 0.18945492068172884, 0.18197942222792537, 0.17699588644737324, 0.2271542904136798, 0.1720186932475422, 0.1719827687308913, 0.17968781466471492, 0.18471021442800578, 0.2173270011896061, 0.4514309362417762, 0.16576632313987041, 0.1657623401083867, 0.16576214334736694, 0.1978792235128574, 0.3081748342508349, 0.1865614540336142, 0.1638146377128494, 0.16381180766416362, 0.16380692357754276, 0.33072825895789837, 0.1725432978737218, 0.16241781652260823, 0.24237052047652044, 0.19710527570692438, 0.21038313463225986, 0.2434538036478607, 0.3720284407765462, 0.23620809545541394, 0.2477024674765833, 0.26361557409253983, 0.18960727165058003, 0.17105076882382053, 0.23013350921244435, 0.21505534832124756, 0.26267445432304354, 0.17585379326115355, 0.17878591299016275, 0.1757139408769399, 0.16213912392265298, 0.17382891606210465, 0.1801544473978278, 0.1620120654943655, 0.1618565024043762, 0.1618474762788449, 0.16158926065361642, 0.26433837371266594, 0.16147069803776168, 0.1632491816294931, 0.1612163407604549, 0.16521349200642535, 0.20108788561653734, 0.1995155236819267, 0.1608447248845836, 0.16686322996890807, 0.17083614621408336, 0.16491460624712811, 0.16490222994830256, 0.16052412387788992, 0.16487846222175204, 0.1664043027734359, 0.1773357390390595, 0.175875859908349, 0.23209492853952512, 0.32234320606441813, 0.18999093877106507, 0.3084606657962819, 0.2649116435604308, 0.24273626878059018, 0.2385192756254288, 0.30668496060671613, 0.2841569243925553, 0.29107106639223096, 0.18456550072915684, 0.21389994582811556, 0.17425214344772907, 0.19970098565429487, 0.1913042776445996, 0.1725545478839795, 0.2740273885489378, 0.27438028822648813, 0.27440110533027745, 0.2006183906288548, 0.1859354779743081, 0.1714534220528236, 0.1856932836660889, 0.17494430343582087, 0.16347812766787018, 0.2393346981742043, 0.24639560476236236, 0.27415045014971146, 0.18535823064804058, 0.271288403030524, 0.27860641337454006, 0.27865579181026473, 0.27961721370881437, 0.2816777759162141, 0.17151154627538134, 0.17152766503651876, 0.29124685103343, 0.3332312929552701, 0.35592841747617204, 0.3580738778422138, 0.3964263537664563, 0.40842594599359816, 0.3036487437244544, 0.3504743677107216, 0.20162577425971884, 0.18703293777499128, 0.26246685840803574, 0.17725817626755044, 0.22443902415065603, 0.17659097409290112, 0.176587314040358, 0.16826761002817492, 0.16826493163496856, 0.19406889725837886, 0.19074659118248424, 0.16517057204573932, 0.1651685773641477, 0.16516001215121257, 0.2767558811635877, 0.18443428504978834, 0.17916331597866145, 0.16946158539663056, 0.1599448418588928, 0.15994263704574982, 0.15994019073813745, 0.15993706228705623, 0.15993650716340574, 0.19532980688277687, 0.17040270473095065, 0.15787602616958657, 0.1578752515055093, 0.1578750758731679, 0.15787444234222214, 0.15787381508385998, 0.1880643410195429, 0.16634520002364592, 0.19335509600082504, 0.1857634561610264, 0.20756127480304748, 0.2164369948662992, 0.6181250862476696, 0.5745137458410114, 0.426618211751864, 0.2054496965414278, 0.21792347531319273, 0.3003506525728703, 0.18028027811430197, 0.3951151414592858, 0.2706310746235697, 0.16955101654146712, 0.17097968995225798, 0.17143364737996314, 0.17147474759099285, 0.17153081483366087, 0.1652802375157221, 0.19990947089935407, 0.20123893794578443, 0.15430974415288223, 0.15430925466872403, 0.15430904043073018, 0.15430846440009766, 0.15430738753494966, 0.15430538419688783, 0.15430512597625945, 0.21135409423510335, 0.15664333403329994, 0.175875859908349, 0.260159551070149, 0.15683300673065775, 0.1744463538257968, 0.17462255915508632, 0.15700068855190064, 0.15702698674232968, 0.1570301468539274, 0.17891392167545556, 0.18999093877106507, 0.2854077240785256, 0.37404194243962147, 0.21957616679568012, 0.2446965633855743, 0.21994833468062966, 0.23832209732475412, 0.31250253269829237, 0.2281623778627852, 0.20540607598262844, 0.19722830605983266, 0.19169878159235726, 0.19841746230867963, 0.2161419315233957, 0.34261811328997116, 0.20825152277298467, 0.18268643902230486, 0.19621427436917546, 0.16860519734081097, 0.1686015098507859, 0.17359867619712782, 0.2740273885489378, 0.27438028822648813, 0.27440110533027745, 0.21633104385988508, 0.15952983620071765, 0.27415045014971146, 0.3720284407765462, 0.19504455641446714, 0.271288403030524, 0.21294226739248462, 0.1559487426081733, 0.15594823671889402, 0.15594823000948713, 0.15594810789828178, 0.15594801530846675, 0.15594723701726787, 0.1559471752907245, 0.15594679688017607, 0.15594670563224242, 0.15594666135015695, 0.1559465338714261, 0.15594645738418758, 0.15594641578586488, 0.15594634734991464, 0.27860641337454006, 0.27865579181026473, 0.27961721370881437, 0.2816777759162141, 0.1642850849601491, 0.210349413615032, 0.29124685103343, 0.3332312929552701, 0.2679886632308962, 0.35592841747617204, 0.3580738778422138, 0.19517786991835223, 0.33102494294561186, 0.3964263537664563, 0.40842594599359816, 0.3036487437244544, 0.34942669824230405, 0.30220108136944457, 0.23884040771829634, 0.24158762082701066, 0.22565222181474162, 0.1790448584963278, 0.17904482357702695, 0.17722105932737975, 0.1977230338083957, 0.19594696173965545, 0.21573560830240138, 0.18433767589714956, 0.1843895583536821, 0.1866570393914352, 0.18332675637690352, 0.20812367966501327, 0.24237052047652044, 0.1706657832027582, 0.17068801876904754, 0.23719629177454185, 0.20593487466713725, 0.2118848843445604, 0.2051199685407958, 0.15771557407301623, 0.24639560476236236, 0.16951614965406245, 0.17091724715025788, 0.25183523605480723, 0.2092300462429169, 0.2033931225759576, 0.20060524468160015, 0.18976674213218356, 0.21750630110762112, 0.33512603225596715, 0.267031910108676, 0.25059420731505816, 0.260159551070149, 0.3720284407765462, 0.29198284648846995, 0.40842594599359816, 0.21198138460289137, 0.1801730620946131, 0.17817908554114026, 0.17892137908744762, 0.1799089770144905, 0.16618906458848992, 0.20838784043538447, 0.26246685840803574, 0.24626505491965062, 0.2462537952182386, 0.24626573660294743, 0.16161302323610496, 0.16161047615813234, 0.16160992499485097, 0.16160778601224413, 0.16660113793123676, 0.16664379456862619, 0.16698177269560985, 0.24268772179641734, 0.1593183475564619, 0.17004992722215823, 0.2546309729963265, 0.20795787147953415, 0.1570311817696995, 0.1570298589778242, 0.15702918350963257, 0.1791538124730314, 0.16681756663381925, 0.25140717800839085, 0.2386281748935237, 0.24707095065544196, 0.17910910376542008, 0.2388607377983515, 0.40842594599359816, 0.2456029062944542, 0.3085891082474834, 0.3036487437244544, 0.30622668058178176, 0.17584995677123025, 0.17706165473759128, 0.23884040771829634, 0.1770667377711761, 0.17445795697026711, 0.19187440044230733, 0.19621427436917546, 0.24158762082701066, 0.16491184652214808, 0.1707460863711963, 0.1707326740612639, 0.17073550121250367, 0.17073622117513304, 0.1707462210907564, 0.17074187024717294, 0.17074748522188263, 0.17074756793543655, 0.17441078773787388, 0.2679886632308962, 0.18556215446736454, 0.18552518374013424, 0.16878534213498655, 0.34942669824230405, 0.18763583843140968, 0.1754532694251882, 0.26361010315166855, 0.1746173750409766, 0.1767318244670725, 0.17389533213203934, 0.24693675733544157, 0.19589004863263645, 0.23832209732475412, 0.2608544626545321, 0.23551785092909258, 0.214503340153127, 0.2628702401736685, 0.3013933605038587, 0.22565222181474162, 0.17959762232938814, 0.3964263537664563, 0.3773115609382819, 0.1550655743457433, 0.20914276176801697, 0.3580738778422138, 0.21054286729949442, 0.1843895583536821, 0.16422494162945153, 0.2054496965414278, 0.18433767589714956, 0.24501688201622426, 0.1977230338083957, 0.19767382339318285, 0.1787209201765576, 0.18332675637690352, 0.17136111525121084, 0.14917783277149338, 0.14917769996788466, 0.14917727022817107, 0.149176818622215, 0.1491767315117264, 0.14917653988581173, 0.14917623181440687, 0.14917524368807064, 0.15425299386250718, 0.20812367966501327, 0.17068801876904754, 0.1549954627828284, 0.1706657832027582, 0.2826092903664558, 0.2434538036478607, 0.24639560476236236, 0.2164369948662992, 0.1866570393914352, 0.18989379593817005, 0.32464147426958545, 0.22050237510951223, 0.3332312929552701, 0.22165158935545984, 0.20056032380798194, 0.2804288927415322, 0.25019777385839526, 0.16617415121542123, 0.1661701893144904, 0.19209510330354307, 0.1968303441438611, 0.17425898830500083, 0.16044436706410956, 0.17271090333627442, 0.1978792235128574, 0.1547326226712642, 0.15473230804971969, 0.15473222211142745, 0.15473193079518252, 0.1547301508529261, 0.15472542861659602, 0.1977230338083957, 0.23460531614688887, 0.22565222181474162, 0.169213555894513, 0.14901213296474652, 0.14901192685850323, 0.14901188680251956, 0.14901173677465343, 0.1490117229371318, 0.14901171419764445, 0.1490114338057587, 0.14901143016430565, 0.14901141341362156, 0.14901117380601014, 0.14901099246164767, 0.14901079509489173, 0.24440898038532194, 0.18678911288799088, 0.26739855403423296, 0.1866570393914352, 0.24639560476236236, 0.2066473109908445, 0.18433767589714956, 0.24707095065544196, 0.1843895583536821, 0.2649116435604308, 0.2092300462429169, 0.26361557409253983, 0.15771557407301623, 0.20593487466713725, 0.2033931225759576, 0.1725545478839795, 0.15042964486952368, 0.20060524468160015, 0.1504750319415573, 0.1505238578601268, 0.25183523605480723, 0.15058373548227794, 0.25059420731505816, 0.18041319212084633, 0.18456550072915684, 0.20309300765585833, 0.155403540239201, 0.17425214344772907, 0.15112744495648023, 0.162984014495543, 0.18377753344868278, 0.16347812766787018, 0.2385192756254288, 0.2051199685407958, 0.16740526530183755, 0.18678911288799088, 0.1632176889363103, 0.16322615979856045, 0.15618420081620968, 0.16324761031850563, 0.1564592465948121, 0.17494430343582087, 0.33512603225596715, 0.21516451009088455, 0.2092319931667802, 0.18772120695675043, 0.19692446462012808, 0.25019777385839526, 0.3720284407765462, 0.32464147426958545, 0.2804288927415322, 0.21573560830240138, 0.24732313624287244, 0.33072825895789837, 0.2550888990127749], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.370299816131592, -5.946000099182129, -6.0960001945495605, -6.230500221252441, -6.230599880218506, -6.44950008392334, -6.449699878692627, -6.195799827575684, -6.470200061798096, -6.358699798583984, -6.598599910736084, -6.598800182342529, -6.350399971008301, -6.598700046539307, -6.229000091552734, -6.509200096130371, -6.6691999435424805, -6.743199825286865, -6.737400054931641, -6.551199913024902, -6.8302998542785645, -6.638400077819824, -6.677800178527832, -6.592100143432617, -6.788899898529053, -7.001800060272217, -7.0019001960754395, -7.001999855041504, -7.001999855041504, -7.001999855041504, -6.764500141143799, -6.837399959564209, -6.587399959564209, -6.960999965667725, -6.745299816131592, -6.146100044250488, -6.401199817657471, -6.462100028991699, -6.425000190734863, -6.429800033569336, -6.429800033569336, -6.140500068664551, -6.30109977722168, -6.30109977722168, -6.301199913024902, -6.405399799346924, -6.4054999351501465, -6.503200054168701, -6.762899875640869, -6.486499786376953, -6.554299831390381, -6.579100131988525, -6.554699897766113, -6.2469000816345215, -6.901000022888184, -6.901100158691406, -6.831399917602539, -6.832099914550781, -6.629300117492676, -6.901000022888184, -6.836100101470947, -6.714200019836426, -6.991499900817871, -6.928800106048584, -7.106900215148926, -7.10699987411499, -7.10699987411499, -7.10699987411499, -7.10699987411499, -6.890699863433838, -6.970900058746338, -6.575099945068359, -6.923799991607666, -5.927999973297119, -6.391600131988525, -6.362500190734863, -6.80019998550415, -6.504300117492676, -6.3907999992370605, -6.602499961853027, -6.67579984664917, -6.800300121307373, -6.789000034332275, -6.8221001625061035, -5.83650016784668, -5.9274001121521, -6.222700119018555, -6.259799957275391, -6.067200183868408, -6.294000148773193, -6.025700092315674, -6.487599849700928, -6.510499954223633, -6.229499816894531, -6.6006999015808105, -6.600800037384033, -6.600900173187256, -6.60099983215332, -6.60099983215332, -6.60099983215332, -6.60099983215332, -6.60099983215332, -6.60099983215332, -6.60099983215332, -6.601099967956543, -6.601099967956543, -6.605000019073486, -6.605199813842773, -6.692299842834473, -6.723999977111816, -6.62939977645874, -6.749899864196777, -6.750199794769287, -6.746200084686279, -6.35129976272583, -6.38040018081665, -6.479100227355957, -6.275100231170654, -6.5971999168396, -6.283299922943115, -6.52839994430542, -6.52839994430542, -6.528600215911865, -6.514100074768066, -6.4593000411987305, -6.674499988555908, -6.651199817657471, -6.137800216674805, -6.674300193786621, -6.746099948883057, -6.7546000480651855, -6.668000221252441, -6.668000221252441, -6.788899898529053, -6.6645002365112305, -6.6641998291015625, -6.853400230407715, -6.853499889373779, -6.853700160980225, -6.764800071716309, -6.642899990081787, -6.872700214385986, -6.552599906921387, -6.564000129699707, -6.906700134277344, -6.9359002113342285, -6.917500019073486, -6.8394999504089355, -6.9816999435424805, -6.676499843597412, -6.594399929046631, -6.845600128173828, -6.6996002197265625, -6.78410005569458, -6.740900039672852, -6.804500102996826, -6.7846999168396, -5.861800193786621, -5.86359977722168, -5.9816999435424805, -6.142199993133545, -6.308499813079834, -6.473800182342529, -6.39870023727417, -6.666600227355957, -6.5493998527526855, -6.727799892425537, -6.760799884796143, -6.750199794769287, -6.262400150299072, -6.845600128173828, -6.845600128173828, -6.745299816131592, -6.807600021362305, -6.86929988861084, -6.8933000564575195, -6.8933000564575195, -6.8933000564575195, -6.8933000564575195, -6.8694000244140625, -6.506999969482422, -6.8694000244140625, -6.640600204467773, -7.02839994430542, -6.962399959564209, -7.0640997886657715, -6.918399810791016, -6.712200164794922, -6.871600151062012, -6.514800071716309, -6.837900161743164, -6.5945000648498535, -6.775599956512451, -6.851799964904785, -6.848800182342529, -5.7453999519348145, -5.896200180053711, -6.404300212860107, -6.094600200653076, -6.633500099182129, -6.731100082397461, -6.767000198364258, -6.767000198364258, -6.767000198364258, -6.593599796295166, -6.160999774932861, -6.583199977874756, -6.450699806213379, -6.471199989318848, -6.473199844360352, -6.9054999351501465, -6.98799991607666, -6.98799991607666, -6.98799991607666, -6.988100051879883, -6.988100051879883, -6.988100051879883, -6.988100051879883, -6.915599822998047, -6.823400020599365, -6.9131999015808105, -6.9903998374938965, -6.905700206756592, -7.030700206756592, -6.732900142669678, -6.627799987792969, -6.643400192260742, -6.6666998863220215, -6.593999862670898, -6.697700023651123, -6.67519998550415, -6.802700042724609, -6.690400123596191, -6.701600074768066, -6.485099792480469, -6.563700199127197, -6.708199977874756, -6.732699871063232, -6.671899795532227, -6.5518999099731445, -6.6859002113342285, -6.730000019073486, -6.743000030517578, -5.801799774169922, -6.362599849700928, -6.165299892425537, -6.491799831390381, -5.833799839019775, -6.201200008392334, -6.880799770355225, -6.4720001220703125, -7.033100128173828, -6.353300094604492, -7.01039981842041, -6.278299808502197, -7.154900074005127, -6.828400135040283, -6.645199775695801, -7.120200157165527, -7.136499881744385, -6.6528000831604, -6.983099937438965, -6.961699962615967, -6.916200160980225, -5.919899940490723, -7.00570011138916, -7.094799995422363, -7.094799995422363, -7.15939998626709, -7.23390007019043, -7.233799934387207, -7.094900131225586, -7.233699798583984, -6.820199966430664, -6.616600036621094, -6.267099857330322, -6.78439998626709, -6.957300186157227, -6.760300159454346, -6.952199935913086, -6.792900085449219, -6.911900043487549, -7.009200096130371, -6.9756999015808105, -6.947199821472168, -5.68779993057251, -5.793600082397461, -6.253699779510498, -6.643499851226807, -6.35860013961792, -6.584400177001953, -6.719799995422363, -6.882500171661377, -6.6971001625061035, -6.327899932861328, -6.406799793243408, -6.122000217437744, -6.904399871826172, -6.94789981842041, -6.998199939727783, -6.96560001373291, -6.543499946594238, -6.517000198364258, -7.139699935913086, -6.388700008392334, -7.1595001220703125, -6.8867998123168945, -6.870200157165527, -7.104400157928467, -7.071100234985352, -6.553199768066406, -6.9369001388549805, -6.335899829864502, -6.394100189208984, -6.648600101470947, -6.468200206756592, -6.793700218200684, -6.96150016784668, -6.9268999099731445, -6.852399826049805, -6.928800106048584, -6.949399948120117, -5.658699989318848, -5.724100112915039, -6.043399810791016, -6.049799919128418, -6.0370001792907715, -6.000699996948242, -6.346099853515625, -6.4766998291015625, -6.549799919128418, -6.604300022125244, -6.6402997970581055, -6.475200176239014, -6.768700122833252, -6.769700050354004, -6.747499942779541, -6.806700229644775, -6.670199871063232, -5.944699764251709, -6.957699775695801, -6.957900047302246, -6.957900047302246, -6.788599967956543, -6.366300106048584, -6.877299785614014, -7.024899959564209, -7.025000095367432, -7.025199890136719, -6.328199863433838, -6.985000133514404, -7.075900077819824, -6.703400135040283, -6.905399799346924, -6.866399765014648, -6.791299819946289, -6.584499835968018, -6.846099853515625, -6.837800025939941, -6.847300052642822, -6.630300045013428, -6.874199867248535, -6.5777997970581055, -6.762199878692627, -6.576700210571289, -6.999300003051758, -6.982999801635742, -7.033199787139893, -7.122300148010254, -7.056700229644775, -7.02239990234375, -7.13670015335083, -7.1545000076293945, -7.155399799346924, -7.185800075531006, -6.697700023651123, -7.199699878692627, -7.200799942016602, -7.214200019836426, -7.209099769592285, -7.0278000831604, -7.060800075531006, -7.2779998779296875, -7.242099761962891, -7.233699798583984, -7.298900127410889, -7.301599979400635, -7.332200050354004, -7.309000015258789, -7.301599979400635, -7.238800048828125, -7.2581000328063965, -7.103700160980225, -7.02400016784668, -7.264500141143799, -7.188000202178955, -7.23859977722168, -7.246699810028076, -5.819499969482422, -5.656799793243408, -5.735099792480469, -5.9039998054504395, -6.427999973297119, -6.365900039672852, -6.663899898529053, -6.531499862670898, -6.589200019836426, -6.717400074005127, -6.352499961853027, -6.352399826049805, -6.352399826049805, -6.689700126647949, -6.769700050354004, -6.87470006942749, -6.795899868011475, -6.908599853515625, -6.992700099945068, -6.620100021362305, -6.594699859619141, -6.501500129699707, -6.922500133514404, -6.560200214385986, -6.560200214385986, -6.5605998039245605, -6.5605998039245605, -6.560299873352051, -7.0696001052856445, -7.075699806213379, -6.6132001876831055, -6.560299873352051, -6.560400009155273, -6.560299873352051, -6.560400009155273, -6.553699970245361, -6.746799945831299, -6.738100051879883, -6.027400016784668, -6.281799793243408, -5.952199935913086, -6.497499942779541, -6.273099899291992, -6.513999938964844, -6.514100074768066, -6.747700214385986, -6.747799873352051, -6.660200119018555, -6.688799858093262, -6.850800037384033, -6.850900173187256, -6.851200103759766, -6.380300045013428, -6.789599895477295, -6.885799884796143, -6.9847002029418945, -7.053199768066406, -7.053299903869629, -7.053400039672852, -7.053500175476074, -7.053599834442139, -6.854300022125244, -7.023900032043457, -7.146200180053711, -7.146299839019775, -7.146299839019775, -7.146299839019775, -7.146299839019775, -6.976500034332275, -7.105299949645996, -6.995200157165527, -7.030700206756592, -6.954699993133545, -6.947400093078613, -6.613100051879883, -6.70959997177124, -6.861599922180176, -7.016499996185303, -6.442200183868408, -6.1620001792907715, -6.757199764251709, -6.012899875640869, -6.421599864959717, -6.89900016784668, -6.9079999923706055, -6.949900150299072, -6.954599857330322, -6.960000038146973, -7.07450008392334, -6.988500118255615, -6.988399982452393, -7.258200168609619, -7.258299827575684, -7.258299827575684, -7.258299827575684, -7.258399963378906, -7.258500099182129, -7.258500099182129, -7.007800102233887, -7.307799816131592, -7.210400104522705, -6.820499897003174, -7.333099842071533, -7.232900142669678, -7.25029993057251, -7.35699987411499, -7.360599994659424, -7.360599994659424, -7.235099792480469, -7.178699970245361, -6.81790018081665, -6.58050012588501, -7.093200206756592, -7.0279998779296875, -7.10230016708374, -7.098400115966797, -7.018400192260742, -7.1479997634887695, -7.185800075531006, -7.198299884796143, -7.205900192260742, -7.199699878692627, -7.194499969482422, -7.158400058746338, -5.7846999168396, -6.416600227355957, -6.359600067138672, -6.604400157928467, -6.604499816894531, -6.746399879455566, -6.336699962615967, -6.336299896240234, -6.33650016784668, -6.607500076293945, -6.947800159454346, -6.485400199890137, -6.1992998123168945, -6.866300106048584, -6.5447001457214355, -6.797500133514404, -7.124199867248535, -7.124199867248535, -7.124199867248535, -7.124199867248535, -7.124199867248535, -7.124300003051758, -7.124300003051758, -7.124300003051758, -7.124300003051758, -7.124300003051758, -7.124300003051758, -7.124300003051758, -7.124300003051758, -7.124300003051758, -6.5447998046875, -6.545000076293945, -6.545000076293945, -6.545300006866455, -7.075399875640869, -6.868800163269043, -6.598100185394287, -6.544899940490723, -6.716700077056885, -6.5447998046875, -6.5447001457214355, -6.971499919891357, -6.6427998542785645, -6.544899940490723, -6.554900169372559, -6.732100009918213, -6.679500102996826, -6.772799968719482, -5.702499866485596, -5.775599956512451, -5.968400001525879, -6.253900051116943, -6.253900051116943, -6.406599998474121, -6.325300216674805, -6.406799793243408, -6.406700134277344, -6.56689977645874, -6.566699981689453, -6.664899826049805, -6.6844000816345215, -6.633600234985352, -6.491799831390381, -6.885700225830078, -6.8856000900268555, -6.5655999183654785, -6.742800235748291, -6.71999979019165, -6.7555999755859375, -7.042900085449219, -6.598999977111816, -6.975599765777588, -6.975399971008301, -6.6031999588012695, -6.803899765014648, -6.8460001945495605, -6.865699768066406, -6.940199851989746, -6.827099800109863, -6.476200103759766, -6.664400100708008, -6.755000114440918, -6.745800018310547, -6.594399929046631, -6.740699768066406, -6.647799968719482, -5.607800006866455, -6.170400142669678, -6.412399768829346, -6.438300132751465, -6.474599838256836, -6.573999881744385, -6.443299770355225, -6.245500087738037, -6.324699878692627, -6.32480001449585, -6.32480001449585, -6.751500129699707, -6.7515997886657715, -6.7515997886657715, -6.751699924468994, -6.744500160217285, -6.746600151062012, -6.762800216674805, -6.4274001121521, -6.854000091552734, -6.810400009155273, -6.4274001121521, -6.631499767303467, -6.967800140380859, -6.967899799346924, -6.967899799346924, -6.839799880981445, -6.913300037384033, -6.507199764251709, -6.573599815368652, -6.573599815368652, -6.882599830627441, -6.730400085449219, -6.575799942016602, -6.814199924468994, -6.808800220489502, -6.814199924468994, -6.113100051879883, -6.682000160217285, -6.719900131225586, -6.421800136566162, -6.727200031280518, -6.775400161743164, -6.720300197601318, -6.719200134277344, -6.533100128173828, -6.942699909210205, -7.028500080108643, -7.02869987487793, -7.029200077056885, -7.029799938201904, -7.029900074005127, -7.030300140380859, -7.031099796295166, -7.0335001945495605, -7.042099952697754, -6.626699924468994, -7.029900074005127, -7.0335001945495605, -7.1616997718811035, -6.446000099182129, -7.083600044250488, -7.15500020980835, -6.753499984741211, -7.183000087738037, -7.180300235748291, -7.207799911499023, -6.880499839782715, -7.117099761962891, -7.004899978637695, -6.954500198364258, -7.0279998779296875, -7.08489990234375, -7.027500152587891, -7.051700115203857, -6.299900054931641, -6.537799835205078, -5.843800067901611, -5.9070000648498535, -6.81820011138916, -6.6656999588012695, -6.128300189971924, -6.701000213623047, -6.912499904632568, -7.0345001220703125, -6.8206000328063965, -6.94350004196167, -6.660200119018555, -6.902699947357178, -6.931700229644775, -7.036200046539307, -7.043000221252441, -7.13700008392334, -7.293799877166748, -7.293799877166748, -7.293799877166748, -7.293900012969971, -7.293900012969971, -7.293900012969971, -7.294000148773193, -7.294099807739258, -7.26140022277832, -6.983399868011475, -7.19350004196167, -7.301799774169922, -7.210899829864502, -6.736999988555908, -6.87939977645874, -6.929500102996826, -7.040800094604492, -7.143700122833252, -7.156300067901611, -6.8983001708984375, -7.102200031280518, -6.924200057983398, -7.1168999671936035, -7.156300067901611, -7.117700099945068, -7.139999866485596, -6.166500091552734, -6.1666998863220215, -6.026400089263916, -6.126800060272217, -6.320199966430664, -6.412700176239014, -6.421999931335449, -6.422100067138672, -6.738800048828125, -6.738800048828125, -6.738800048828125, -6.738800048828125, -6.738900184631348, -6.739200115203857, -6.768799781799316, -6.746099948883057, -6.793700218200684, -7.085899829864502, -7.2266998291015625, -7.2266998291015625, -7.2266998291015625, -7.226799964904785, -7.226799964904785, -7.226799964904785, -7.226799964904785, -7.226799964904785, -7.226799964904785, -7.226799964904785, -7.226799964904785, -7.226900100708008, -6.793000221252441, -7.029099941253662, -6.872300148010254, -7.105500221252441, -6.9730000495910645, -7.108699798583984, -7.152400016784668, -7.085000038146973, -7.192699909210205, -7.146599769592285, -7.181000232696533, -7.207799911499023, -7.432700157165527, -7.220399856567383, -7.364299774169922, -7.537399768829346, -7.721099853515625, -7.436200141906738, -7.727799892425537, -7.735199928283691, -7.22790002822876, -7.744200229644775, -7.249899864196777, -7.579800128936768, -7.566999912261963, -7.510799884796143, -7.783899784088135, -7.686999797821045, -7.829800128936768, -7.766300201416016, -7.655799865722656, -7.773200035095215, -7.405200004577637, -7.560200214385986, -7.766300201416016, -7.661799907684326, -7.803100109100342, -7.8043999671936035, -7.85099983215332, -7.807799816131592, -7.853400230407715, -7.746399879455566, -7.117000102996826, -7.592199802398682, -7.630899906158447, -7.708899974822998, -7.678400039672852, -7.5395002365112305, -7.354000091552734, -7.517000198364258, -7.590099811553955, -7.69789981842041, -7.6768999099731445, -7.627699851989746, -7.677800178527832], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7887, 1.7816, 1.7013, 1.6247, 1.6246, 1.4905, 1.4904, 1.487, 1.456, 1.4504, 1.3813, 1.3571, 1.3465, 1.3398, 1.3118, 1.2635, 1.2547, 1.219, 1.2171, 1.2126, 1.2045, 1.1683, 1.1672, 1.1671, 1.1273, 1.1048, 1.1047, 1.1047, 1.1046, 1.1046, 1.0632, 1.0577, 0.9525, 1.0885, 0.9952, 0.6987, 0.8144, 0.7709, 0.4929, 1.5168, 1.5168, 1.511, 1.464, 1.4639, 1.4639, 1.3743, 1.3262, 1.2993, 1.2899, 1.2579, 1.2422, 1.2277, 1.2071, 1.1994, 1.1609, 1.1608, 1.1423, 1.1412, 1.1409, 1.1393, 1.1382, 1.0814, 1.054, 1.0427, 1.0321, 1.032, 1.032, 1.032, 1.032, 1.031, 1.0302, 1.0197, 1.0237, 0.9168, 0.9613, 0.8705, 0.9675, 0.7549, 0.5271, 0.6131, 0.7364, 0.7553, 0.6852, 0.6988, 1.8884, 1.8079, 1.6527, 1.646, 1.6298, 1.6245, 1.5215, 1.4978, 1.4824, 1.4707, 1.4201, 1.42, 1.42, 1.4199, 1.4198, 1.4198, 1.4198, 1.4198, 1.4198, 1.4198, 1.4198, 1.4198, 1.4171, 1.4169, 1.3551, 1.3322, 1.294, 1.2867, 1.2702, 1.2651, 1.0455, 1.0348, 0.9836, 0.5697, 0.3207, 1.6468, 1.4834, 1.4834, 1.4832, 1.4685, 1.4066, 1.3695, 1.3591, 1.3191, 1.3089, 1.308, 1.3001, 1.2884, 1.2799, 1.2678, 1.2556, 1.2523, 1.2473, 1.2472, 1.2471, 1.2053, 1.203, 1.1956, 1.1901, 1.1658, 1.1639, 1.1568, 1.1414, 1.134, 1.1132, 1.0727, 0.7581, 1.0459, 0.7705, 0.8797, 0.6062, 0.8306, 0.5076, 1.9076, 1.9066, 1.8402, 1.6839, 1.5696, 1.4928, 1.4873, 1.3904, 1.3618, 1.3453, 1.3207, 1.2872, 1.2584, 1.2566, 1.2566, 1.2527, 1.2475, 1.2258, 1.2199, 1.2199, 1.2199, 1.2199, 1.2189, 1.1817, 1.1538, 1.1439, 1.1027, 1.1015, 1.0855, 1.0707, 1.0579, 1.0284, 0.7775, 0.9938, 0.7526, 0.6813, 0.6881, 0.6319, 1.9474, 1.9079, 1.5889, 1.3517, 1.336, 1.3325, 1.3267, 1.3266, 1.3266, 1.3235, 1.3083, 1.2959, 1.2076, 1.1858, 1.1837, 1.1555, 1.1548, 1.1548, 1.1548, 1.1547, 1.1547, 1.1547, 1.1547, 1.1477, 1.1333, 1.1259, 1.1248, 1.1217, 1.1003, 1.0739, 1.03, 1.0082, 1.0044, 0.9664, 0.9706, 0.9555, 1.0263, 0.9477, 0.9401, 0.7741, 0.8331, 0.9333, 0.9561, 0.7908, 0.366, 0.7049, 0.8673, 0.546, 1.5366, 1.513, 1.4621, 1.4536, 1.3818, 1.2699, 1.2459, 1.2038, 1.1253, 1.1209, 1.013, 1.0106, 1.0018, 1.0007, 1.0, 0.9886, 0.9734, 0.97, 0.9427, 0.9427, 0.927, 0.9249, 0.9125, 0.9112, 0.9093, 0.9044, 0.8927, 0.8583, 0.8573, 0.852, 0.8374, 0.7741, 0.6508, 0.7551, 0.8065, 0.6364, 0.7808, 0.56, 0.6512, 0.7446, 0.6215, 0.3976, 2.0522, 1.5448, 1.3737, 1.3452, 1.3219, 1.3156, 1.2724, 1.2496, 1.2309, 1.2178, 1.2151, 1.1703, 1.1438, 1.0895, 1.0595, 1.0594, 1.0544, 1.0495, 1.0409, 1.0265, 1.0245, 1.0192, 1.0172, 1.0023, 0.9947, 0.9737, 0.9577, 0.9531, 0.953, 0.9502, 0.9225, 0.9165, 0.936, 0.8376, 0.5598, 0.6888, 0.4031, 2.1079, 2.0713, 1.8776, 1.8735, 1.8392, 1.8243, 1.6725, 1.5781, 1.4775, 1.4633, 1.4551, 1.3707, 1.3551, 1.3543, 1.3328, 1.246, 1.2198, 1.2144, 1.2031, 1.203, 1.203, 1.1952, 1.1745, 1.1654, 1.1478, 1.1478, 1.1476, 1.1419, 1.1358, 1.1054, 1.0776, 1.0823, 1.0562, 0.9852, 0.768, 0.9606, 0.9214, 0.8496, 1.3962, 1.2553, 1.255, 1.1384, 1.1238, 1.1025, 1.1023, 1.0694, 1.0607, 1.0567, 1.0552, 1.0471, 1.0302, 1.0294, 1.0006, 0.9966, 0.9874, 0.9754, 0.9745, 0.9551, 0.94, 0.9148, 0.913, 0.9122, 0.8971, 0.8672, 0.8646, 0.8608, 0.8572, 0.8554, 0.8546, 0.8436, 0.7206, 0.4719, 0.76, 0.3518, 0.4534, 0.5328, 1.9775, 1.8889, 1.8869, 1.6939, 1.6255, 1.5401, 1.4471, 1.4431, 1.4284, 1.4034, 1.3057, 1.3046, 1.3044, 1.2804, 1.2763, 1.2524, 1.2514, 1.1984, 1.1821, 1.1735, 1.1698, 1.1563, 1.1267, 1.1081, 1.0814, 1.0809, 1.0775, 1.0704, 1.0572, 1.051, 0.9841, 0.9023, 0.8363, 0.8304, 0.7285, 0.7055, 0.8088, 0.6741, 1.9377, 1.7584, 1.7491, 1.5964, 1.5848, 1.5836, 1.5835, 1.3982, 1.3981, 1.343, 1.3317, 1.3137, 1.3136, 1.3134, 1.268, 1.2646, 1.1974, 1.1542, 1.1434, 1.1433, 1.1433, 1.1431, 1.1431, 1.1425, 1.1094, 1.0634, 1.0634, 1.0634, 1.0634, 1.0633, 1.0581, 1.0521, 1.0118, 1.0163, 0.9813, 0.9468, 0.2317, 0.2083, 0.354, 0.9298, 1.4451, 1.4045, 1.3197, 1.2794, 1.2491, 1.2393, 1.2219, 1.1774, 1.1725, 1.1667, 1.0893, 0.9851, 0.9786, 0.9743, 0.9742, 0.9742, 0.9742, 0.9741, 0.974, 0.974, 0.9101, 0.9097, 0.8913, 0.8897, 0.8832, 0.877, 0.8585, 0.8583, 0.8544, 0.8544, 0.8494, 0.8458, 0.7996, 0.7666, 0.7866, 0.7435, 0.7758, 0.6995, 0.5084, 0.6934, 0.7606, 0.7888, 0.8096, 0.7814, 0.7011, 0.2765, 2.148, 1.6471, 1.6326, 1.5395, 1.5394, 1.3683, 1.3215, 1.3206, 1.3204, 1.2872, 1.2514, 1.1723, 1.1531, 1.1319, 1.1236, 1.1129, 1.0978, 1.0977, 1.0977, 1.0977, 1.0977, 1.0977, 1.0977, 1.0977, 1.0977, 1.0977, 1.0977, 1.0976, 1.0976, 1.0976, 1.0968, 1.0965, 1.0931, 1.0854, 1.0945, 1.0539, 0.9992, 0.9178, 0.9638, 0.8519, 0.8461, 1.0261, 0.8265, 0.7441, 0.7043, 0.8235, 0.7357, 0.7876, 2.0931, 2.0086, 1.8841, 1.83, 1.83, 1.6874, 1.6593, 1.5868, 1.4907, 1.4878, 1.4877, 1.3773, 1.3758, 1.2997, 1.2892, 1.246, 1.246, 1.237, 1.2011, 1.1954, 1.1922, 1.1678, 1.1655, 1.163, 1.1548, 1.1394, 1.1241, 1.1104, 1.1045, 1.0855, 1.0621, 0.9808, 1.0197, 0.9926, 0.9644, 0.7581, 0.8541, 0.6113, 2.3072, 1.9071, 1.6763, 1.6462, 1.6044, 1.5844, 1.4887, 1.4558, 1.4404, 1.4403, 1.4403, 1.4348, 1.4347, 1.4346, 1.4346, 1.4114, 1.409, 1.3907, 1.3523, 1.3466, 1.325, 1.3042, 1.3026, 1.2472, 1.2471, 1.2471, 1.2434, 1.2413, 1.2372, 1.2229, 1.1882, 1.2008, 1.0651, 0.6834, 0.9536, 0.7307, 0.7414, 1.434, 1.4199, 1.3751, 1.3739, 1.3678, 1.3344, 1.2944, 1.273, 1.2511, 1.2234, 1.1027, 1.1027, 1.1021, 1.1015, 1.1014, 1.101, 1.1002, 1.0978, 1.068, 1.0538, 1.0182, 1.0148, 0.9811, 0.9692, 0.9533, 0.9491, 0.9435, 0.9258, 0.9166, 0.9052, 0.8818, 0.8768, 0.793, 0.753, 0.7817, 0.8182, 0.6723, 0.5114, 1.5526, 1.543, 1.4452, 1.4314, 1.4094, 1.2627, 1.2624, 1.2207, 1.1419, 1.1357, 1.1257, 1.1112, 1.1099, 1.0819, 1.0531, 1.0494, 1.0172, 0.9907, 0.9725, 0.9725, 0.9725, 0.9724, 0.9724, 0.9724, 0.9724, 0.9723, 0.9715, 0.9499, 0.9381, 0.9263, 0.9209, 0.8904, 0.8972, 0.8351, 0.8534, 0.8985, 0.8687, 0.5904, 0.7734, 0.5384, 0.7535, 0.814, 0.5175, 0.6093, 1.9919, 1.9918, 1.9871, 1.8624, 1.7907, 1.7808, 1.6979, 1.5617, 1.491, 1.491, 1.491, 1.491, 1.4909, 1.4906, 1.2158, 1.0675, 1.0588, 1.0544, 1.0407, 1.0407, 1.0407, 1.0407, 1.0407, 1.0407, 1.0407, 1.0407, 1.0407, 1.0406, 1.0406, 1.0406, 0.9796, 1.0123, 0.8104, 0.9367, 0.7915, 0.8318, 0.9022, 0.6767, 0.8617, 0.5455, 0.747, 0.4891, 0.7779, 0.7235, 0.592, 0.5833, 0.5369, 0.534, 0.5299, 0.5222, 0.5148, 0.5128, 0.4977, 0.4964, 0.4865, 0.447, 0.4415, 0.4239, 0.4236, 0.4115, 0.4019, 0.4016, 0.3919, 0.3877, 0.3848, 0.3797, 0.3733, 0.3719, 0.3694, 0.3684, 0.3652, 0.3606, 0.3399, 0.3079, 0.2971, 0.3276, 0.3102, 0.2097, -0.0015, -0.0283, 0.045, 0.1995, 0.0838, -0.1575, 0.0521]}, \"token.table\": {\"Topic\": [], \"Freq\": [], \"Term\": []}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [10, 17, 14, 19, 3, 4, 13, 2, 12, 15, 8, 18, 16, 11, 5, 1, 6, 7, 20, 9]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el7521261727016326099861003\", ldavis_el7521261727016326099861003_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el7521261727016326099861003\", ldavis_el7521261727016326099861003_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el7521261727016326099861003\", ldavis_el7521261727016326099861003_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.display(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "topic_modeling.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
